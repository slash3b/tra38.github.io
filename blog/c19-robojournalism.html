<!DOCTYPE html>
<head>
  <title> Culture - Robojournalists vs. Humans </title>
  <meta charset="UTF-8">
  <link rel="stylesheet" type="text/css" href="/stylesheets/default.css">
  <link href='http://fonts.googleapis.com/css?family=Slabo+27px' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/stylesheets/blog-stylesheet.css">
  <script type="text/javascript">
    var _mfq = _mfq || [];
    (function() {
      var mf = document.createElement("script");
      mf.type = "text/javascript"; mf.async = true;
      mf.src = "//cdn.mouseflow.com/projects/1771b82f-f215-4af9-ae2e-f35186702620.js";
      document.getElementsByTagName("head")[0].appendChild(mf);
    })();
  </script>
</head>

<main>
<section class="socialmedia">
    <a href="http://www.linkedin.com/in/trali"><img src="/img/linkedin.png" /></a>
    <a href="http://twitter.com/Tariq_Ali38"><img src="/img/twitter.png" /></a>
    <a href="https://github.com/tra38"><img src="/img/github_32.png" /></a>
    </section>
    <section class="links">
      <a href="/index.html">Home/Portfolio</a>
      <a href="/blog/index.html">Blog</a>
    </section>
  <h1>Robojournalists vs. Humans</h1>
  <h2>The German Study</h2>
  <h4>07 September 2015</h4>

  <section>
  <p>Automated Insights and Narrative Science are two companies that specialize in producing software that can write news articles. But how do these news articles stack up to the human-written competition? A German researcher attempts to find out.</p>

<p>In the peer-reviewed article <a href="http://kau.diva-portal.org/smash/get/diva2:699641/FULLTEXT01.pdf">"Enter the robot journalist: users’ perceptions of automated content"</a>, researchers randomly gave German undergraduate students one of two articles. One article was written by a human, and another was written by a program called "Statsheet" (which was created by Automated Insights). The German students were to read the article, rate it, and then say whether the article was written by a human being or a bot.</p>

<p>The researchers asked two questions:</p>

<p>1) Can the research students consistently identify whether an article is written by a human or a bot? - The answer is a resounding "NO". While a majority of students correctly identified the bot-written article as being written by a bot, a majority of students also identified the <strong>human</strong>-written article as being written by a bot. There is no statistically significant difference between how the students 'evaluated' whether the article was written by a human or a bot.</p>

<p>2) Are bots able to write prose of equal quality and crediblity as that of humans? - The answer is "Yes, with one exception". There was no statistically significant difference between the quality of the journalism of the human and the bot...<em>except</em> for the fact that the human's article was seen as more pleasant to read.</p>

<p>(As a tangentical side note, the students rated the bot's article was being more informative, accurate, trustworthy, and objective...though the bot's article was also rated as more boring to read too. The students also rated the human's article as being well-written and coherent.</p>

<p>The reason this note is tangentical is that these results are not "statistically significant"; if you were to run this same experiment with a different population, you would likely get different results.)</p>

<p>Conclusion: The "robojournalists" are able to produce journalism that is able to equal that of the human competition. There are limits to the robojournalists though. They are unable to write prose that is 'pleasent to read'. This may be a sign of limits to robojournalists' creativity, which would give humans the edge. For now.</p>

  </section>
  <a href="index.html">Return back to Blog Index</a>
</main>

