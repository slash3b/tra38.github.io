<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tariq Ali&#39;s Blog</title>
    <description>A blog dedicated to showcasing my talents</description>
    <link>tra38.github.io/blog/</link>
    <atom:link href="tra38.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 12 Nov 2016 10:01:44 -0600</pubDate>
    <lastBuildDate>Sat, 12 Nov 2016 10:01:44 -0600</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>C25 Fear</title>
        <description>![CDATA[Today, many developers feel the need to express their non-technical political opinions online...in a wide variety of different, public forums (Twitter, Facebook, blog posts, comments on blog posts, etc). I can understand why people may feel the to express their own views to random strangers on the Internet. After all, politics is an important aspect of a civil society, and it is essential to understand how a country is run. I, myself, have posted Tweets about non-technical issues (mostly condemning the growing national debt, the polarization of American society and the rise of extremist politics), and may have posted comments on popular blogs using dubious pseudonyms.
]</description>
        <content>&lt;p&gt;Today, many developers feel the need to express their &lt;em&gt;non-technical&lt;/em&gt; political opinions online...in a wide variety of different, public forums (Twitter, Facebook, blog posts, comments on blog posts, etc). I can understand why people may feel the to express their own views to random strangers on the Internet. After all, politics is an important aspect of a civil society, and it is essential to understand how a country is run. I, myself, have posted Tweets about non-technical issues (mostly condemning the growing national debt, the polarization of American society and the rise of extremist politics), and may have posted comments on popular blogs using dubious pseudonyms.&lt;/p&gt;

&lt;p&gt;However, this tendency to &quot;speak your mind to random strangers on the Internet&quot; as being very...problematic.  While some of these strangers are automated bots just crawling for text, many of these strangers are real, live human beings. These human beings may:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Disagree with me entirely because it does not fit within their own preconceived biases&lt;/li&gt;
&lt;li&gt;Agree with me entirely because it fits within their own preconceived biases&lt;/li&gt;
&lt;li&gt;Reinterpret my opinion so that it acts to reinforce their own preconceived biases&lt;/li&gt;
&lt;li&gt;Agree with me on &lt;em&gt;most&lt;/em&gt; of my opinion, but disagrees with a minor aspect of the opinion that actually undermines my whole argument&lt;/li&gt;
&lt;li&gt;Agree with my opinion until they actually read my terrible arguments in favor of it, believe that the opinion itself must be stupid, and then &lt;em&gt;change their opinion&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Not actually care because they&#39;re just wasting time on the Internet&lt;/li&gt;
&lt;li&gt;Etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And these human beings may have different motives for even finding my article. They may:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Have an opinion and want to hear someone else say it in a different manner&lt;/li&gt;
&lt;li&gt;Have an opinion and want to hear flawed arguments against it to make their own opinion look smarter&lt;/li&gt;
&lt;li&gt;Have an opinion and only want to &quot;know the enemy&quot; by reading an argument against it&lt;/li&gt;
&lt;li&gt;Want to read something funny to pass the time&lt;/li&gt;
&lt;li&gt;Actually want to learn about an issue (very unlikely, I admit)&lt;/li&gt;
&lt;li&gt;Etc.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;There&#39;s a lot that can go wrong when conveying information online to random strangers, and it is very hard to get feedback form these users on why they are reading my opinion and whether I successfully expressed the opinion correctly. As a result, it is very easy for you to make a mistake when expressing your political opinion, and to do lasting damage as a result of your carelessness.&lt;/p&gt;

&lt;p&gt;And while having a political opinion is good, expressing it does seems to require a little more deftness that I don&#39;t really know I have. If you argue a cause incorrectly, then you might end up damaging your cause (instead of helping it). If you are preaching to an echo chamber, you&#39;re really just wasting your time. If your opinion is uninformed (or worse, just &lt;em&gt;utterly wrong&lt;/em&gt;), then you&#39;re causing real damage to society.&lt;/p&gt;

&lt;p&gt;So if you have no feedback on the success of your writing, and no confidence that what you&#39;re saying is even right...why bother speaking in public? Self-censorship seems more justified to me in this case (and sharing political opinions should be done in the semi-privacy of one&#39;s own home or job).&lt;/p&gt;

&lt;p&gt;In addition, as a developer, I build tools that can ideally be used by any random stranger...including by those who disagree with me. And I find that pretty odd. The tools that I build are probably much more impactful than the opinions I utter on the Internet...and in fact, can be used to undermine my opinions entirely. Consider this hypothetical example:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I hate spam. I write excellent blog posts against spam, how to identify spam, what can be done to filter out spam, etc., etc., and they receive rave reviews from other people who read it.&lt;/li&gt;
&lt;li&gt;Concidentially, I am a contributor to &lt;a href=&quot;https://github.com/maetl/calyx&quot;&gt;Calyx&lt;/a&gt; - &quot;[a] Ruby library for generating text with declarative recursive grammars&quot;.&lt;/li&gt;
&lt;li&gt;Spammers download Calyx and uses it to generate unique spam emails.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Since I built the program that allowed people to send spam, does it really matter how many blog posts I written against spam? Yes, I didn&#39;t intend for the program to be used in that fashion, but &lt;em&gt;intent&lt;/em&gt; doesn&#39;t really matter, does it? I share some responsibility for building the tool. I was indirectly responsible for the spam. And it means that my arguments against spam were unintentionally stupid.&lt;/p&gt;

&lt;p&gt;This is not much of a problem if I decide to only work on proprietary projects that I have previously  vetted as fitting my political opinions, but that would seem fairly limiting. Most proprietary projects today are dependent on &quot;open source&quot; programs, and it is generally accepted convention to &#39;contribute back&#39; to the open source community.&lt;/p&gt;

&lt;p&gt;&quot;Open source&quot;, that great buzzword of tech enthusiasts everwhere, spurn any limitations on how you use technology. Freedom 0 of &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Free_Software_Definition#The_definition_and_the_Four_Freedoms&quot;&gt;FSF&#39;s Four Freedoms&lt;/a&gt; is:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The freedom to run the program as you wish, for any purpose.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And &lt;a href=&quot;https://opensource.org/docs/osd&quot;&gt;the Open Source Definition&lt;/a&gt; has Clause 6, &quot;No Discrimination Against Fields of Endeavor&quot;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The license must not restrict anyone from making use of the program in a specific field of endeavor. For example, it may not restrict the program from being used in a business, or from being used for genetic research.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The &lt;a href=&quot;http://www.json.org/license.html&quot;&gt;JSON License&lt;/a&gt; is considered a non-&quot;open source&quot; license simply because it demands &quot;The Software shall be used for Good, not Evil.&quot; It is a rather toothless and unenforcable limitation, because anyone can define what they are doing is as &quot;Good, not Evil&quot;, yet the fact that it even bothers to sugget that software should be used ethically has led to many arguments. &lt;a href=&quot;https://github.com/jshint/jshint/issues/1234&quot;&gt;Many programs must be rewritten&lt;/a&gt; so that they could then be relicensed to a &#39;proper&#39; open source license.&lt;/p&gt;

&lt;p&gt;I&#39;m not saying that &quot;open source&quot; is &lt;em&gt;bad&lt;/em&gt;. I&#39;m just saying that it&#39;s very absurd to publicly advocate for a policy position, and that the same time, gleefully create software for people who will use it against your policy position. I should either stop contributing to open source, or stop speaking. I chose the latter.&lt;/p&gt;

&lt;p&gt;Therefore, I impose upon myself an indefinite moratorium on posting political opinions on &lt;em&gt;non-technical&lt;/em&gt; issues in public settings (especially on Twitter and my personal blog). If I am to speak about &lt;em&gt;non-technical&lt;/em&gt; issues within a public setting, I must first lift this moratorium -- and explain why I feel the pressing need to do so, knowing that &quot;speaking out&quot; has a high chance of backfiring and that I am unable to control the &lt;em&gt;users&lt;/em&gt; of the open-source projects that I contribute to.&lt;/p&gt;

&lt;p&gt;Now, I am only limiting myself to commenting on &lt;em&gt;non-technical&lt;/em&gt; issues. I can still write technical opinions on major issues such as &quot;tabs versus spaces&quot;, how to define clean code, the proper role of automation in society, etc. These technical opinions are probably just as heated an passionate as political opinions, but seem qualitatively different because they focus less on &lt;em&gt;what&lt;/em&gt; you should do and more on &lt;em&gt;how&lt;/em&gt; you should do it.&lt;/p&gt;

&lt;p&gt;There&#39;s less of a need to worry about convenying information wrongly to strangers. Most of the time, technical arguments tend to have objective answers, and it&#39;s very easy to check if they are correct or not. Even on issues where subjectivity exists, there&#39;s usually wide areas of agreement between content creators...and you can usually synthesize together your own truth about technology. Technical arguments have (so far) avoided &lt;a href=&quot;http://www.nytimes.com/2014/06/12/upshot/polarization-is-dividing-american-society-not-just-politics.html?_r=0&quot;&gt;the polarization that had infected most of American society&lt;/a&gt;, and so it is much easier to divorce feeling and emotion from the technical arguments being made (although it is still very difficult).&lt;/p&gt;

&lt;p&gt;Worries about people using my works for goals I dislike has also been reduced: I may hate spammers, but I would also want them to perform their job effectively and ensure that their codebase is maintainable. It is reasonable to want people to succeed at their task while at the same time disliking the fact that they are doing the task in the first place.&lt;/p&gt;

&lt;p&gt;The Internet is a revolutionary technology that enables communication with a wide variety of people...even people that I will never know or meet. These random strangers, the &quot;silent majority&quot;, that consumes the work that I produce (software and words), matters to a rather unhealthy degree. Perhaps, in the good old days, when it was hard to communicate your ideas to others, could you afford to take a strong moral stand without fear of your words backfiring or your actions hypocritically underming your moral stand. Today, we don&#39;t have that luxury.&lt;/p&gt;

&lt;p&gt;Technology is ruthlessly amoral. It is the humans that decide how to deal with it.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 11 Nov 2016 00:00:00 -0600</pubDate>
        <link>tra38.github.io/blog/c25-fear.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c25-fear.html</guid>
        
        
      </item>
    
      <item>
        <title>C24 Player Piano</title>
        <description>![CDATA[Recently, the term "Human-Machine Collabaration" has came in the vogue, to describe a sort of alliance between mankind and their tools to accomplish a specific purpose. There has been much talk about the potentials of such collabaration. There has been less talk about its dangers.
]</description>
        <content>&lt;p&gt;Recently, the term &quot;Human-Machine Collabaration&quot; has came in the vogue, to describe a sort of alliance between mankind and their tools to accomplish a specific purpose. There has been much talk about the potentials of such collabaration. There has been less talk about its dangers.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Creativity has always been a collaborative act. We can now increasingly count machines as members of our team as well.---&lt;a href=&quot;https://medium.com/@lux_capital/the-coming-human-machine-partnership-in-creativity-626ddb6a5f7a#.qh04vmdse&quot;&gt;The Coming Human-Machine Partnership in Creativity&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The debate between advocates of artificial intelligence (AI) and defenders of human-centric approaches presents a false dichotomy. Machines can certainly help solve the problems facing humans, but they can rarely do so alone. To be most effective, machines must learn from people and about people. Creating and implementing accurate AI systems requires the input of human knowledge. ---&lt;a href=&quot;https://www.oreilly.com/ideas/how-human-machine-collaboration-has-automated-the-data-catalog&quot;&gt;How human-machine collaboration has automated the data catalog&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We will train machines that continue learning through interacting with other humans in different environments. In turn, the machines will train us on how to train them to get the best value out of human-machine collaboration.---&lt;a href=&quot;https://trainingmag.com/human-machine-collaboration&quot;&gt;Human-Machine Collaboration&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At Tamr, “Machine Driven, Human Guided” goes well beyond a pithy tagline [not that we have anything against pith]. It’s our founding philosophy, the idea that humans and machines should not just collaborate, but iterate on problems that can’t be solved manually or through automation alone. In other words, algorithms v. humans is not an either-or decision. “Together” is possible, with the proper technology and process.---&lt;a href=&quot;http://www.tamr.com/tamrs-take-on-human-machine-collaboration/&quot;&gt;Tamr’s Take … On Human-Machine Collaboration&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In a sense, a math model is the equivalent of a metaphor, a descriptive simplification. It usefully distills, but it also somewhat distorts. So at times, a human helper can provide that dose of nuanced data that escapes the algorithmic automaton. “Often, the two can be way better than the algorithm alone,” Mr. King said.---&lt;a href=&quot;http://www.nytimes.com/2015/04/07/upshot/if-algorithms-know-all-how-much-should-humans-help.html?_r=2&amp;amp;abt=0002&amp;amp;abg=0&quot;&gt;If Algorithms Know All, How Much Should Humans Help?&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Player_Piano_(novel)&quot;&gt;&lt;em&gt;Player Piano&lt;/em&gt;&lt;/a&gt; is Kurt Vonguett Jr.&#39;s first novel, about a dystopian United States government. It wasn&#39;t a good novel to read, especially when compared to his later novels. The book&#39;s text has not aged well, with its racism and sexism rather distracting. But the book&#39;s &lt;em&gt;ideas&lt;/em&gt; are still relevant to the modern day. I once had a plan to write a hard science-fiction novel about the dangers of uncontrolled technological progress without societial regulation, but such a novel would have just been a poorly-written, politically-correct version of &lt;em&gt;Player Piano&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;But Player Piano&#39;s dystopian society also involved a darker, more pessimistic view of &quot;human-machine collaboration&quot; as well. This view is presented in the form of the supercomputer EPICAC XIV.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;This is EPICAC XIV,&quot; said Halyard. &quot;It&#39;s an electronic computing machine - a brain, if you like. This chamber alone, the smallest of the thirty-one used, contains enough wire to reach from here to the moon four times. There are more vacuum tubes in the entire instrument than there were vacuum tubes in the State of New York before World War II.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;EPICAC XIV is a Narrow AI. It is narrowly designed to handle a specific task - &lt;a href=&quot;https://en.wikipedia.org/wiki/Economic_calculation_problem#Use_of_technology&quot;&gt;resource allocation in the United States&lt;/a&gt;. You would not ask EPICAC XIV to write a poem, to bake a cake, or to drive a car. And yet...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;EPICAC XIV, though undedicated, was already at work, deciding how many refrigerators, how many lamps, how many turbine-generators, how many hub caps, how many dinner plates, how many door knobs, how many rubber heels, how many television sets, how many pinochle decks - how many everything America and her customers could have and how much they would cost. And it was EPICAC XIV who would decide for the coming years how many engineers and managers and research men and civil servants, and of what skills, would be needed in order to deliver the goods; and what I.Q. and aptitude levels would separate the useful men from the useless ones, and how many Reconstruction and Reclamation Corps men and how many soldiers could be supported at what pay level and where, and . . .&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;EPICAC XIV is not Skynet. It still requires human lackies. Humans has to gather the Big Data that EPICAC XIV uses for its calcuations, and humans has to carry out EPICAC XIV&#39;s recommendations. So...why exactly do you need to use EPICAC XIV as a middleman? Why not just use humans to perform the calculations? Because humans are just plain inferior to EPICAC&#39;s genius.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Given the facts by human beings, the war-born EPICAC series had offered the highly informed guidance that the reasonable, truth-loving, brilliant, and highly trained core of American genius could have delivered had they had inspired leadership, boundless resources, and two thousand years.&lt;/p&gt;

&lt;p&gt;... EPICAC XIV could consider simultaneously hundreds or even thousands of sides of a question utterly fairly, that EPICAC XIV was wholly free of reason - muddying emotions, that EPICAC XIV never forgot anything - that, in short, EPICAC XIV was dead right about everything.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There is an argument to be made that EPICAC XIV is engaging in &quot;human-machine collaboration&quot;. After all, it is the humans that built EPICAC XIV, curate the data that is then given to EPICAC XIV, and carried out EPICAC XIV&#39;s recommendations. But this is not an &lt;em&gt;equal&lt;/em&gt; collaboration, as this dialog between Paul and Katharine demonstrates.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;As Paul passed Katharine Finch&#39;s desk on his way into his office, she held out his typewritten speech. &quot;That&#39;s very good, what you said about the Second Industrial Revolution,&quot; she said.&lt;/p&gt;

&lt;p&gt;&quot;Old, old stuff.&quot;&lt;/p&gt;

&lt;p&gt;&quot;It seemed very fresh to me - I mean that part where you say how the First Industrial Revolution devalued muscle work, then the second one devalued routine mental work. I was fascinated.&quot;&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;&quot;Do you suppose there&#39;ll be a Third Industrial Revolution?&quot;&lt;/p&gt;

&lt;p&gt;Paul paused in his office doorway. &quot;A third one? What would that be like?&quot;&lt;/p&gt;

&lt;p&gt;&quot;I don&#39;t know exactly. The first and second ones must have been sort of inconceivable at one time.&quot;&lt;/p&gt;

&lt;p&gt;&quot;To the people who were going to be replaced by machines, maybe. A third one, eh? In a way, I guess the third one&#39;s been going on for some time, if you mean thinking machines. That would be the third revolution, I guess - machines that devaluate human thinking. Some of the big computers like EPICAC do that all right, in specialized fields.&quot;&lt;/p&gt;

&lt;p&gt;&quot;Uh-huh,&quot; said Katharine thoughtfully. She rattled a pencil between her teeth. &quot;First the muscle work, then the routine work, then, maybe, the real brainwork.&quot;&lt;/p&gt;

&lt;p&gt;&quot;I hope I&#39;m not around long enough to see that final step. ...&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;EPICAC XIV is handling all of the &quot;brainwork&quot; in thinking about the problem of resource allocation, leaving the humans to worry about the menial tasks necessary to keep EPICAC XIV running. Collaboration matters, but the human involvement in this collaboration is token and marginal at best.&lt;/p&gt;

&lt;p&gt;And, as a result, humanity suffers from an inferiority complex, even going so far as to trust implicitly the machine&#39;s choices...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;President Lynn was explaining what EPICAC XIV would do for the millions of plain folks, and Khashdrahr was translating for the Shah. Lynn declared that EPICAC XIV was, in effect, the greatest individual in history, that the wisest man that had ever lived was to EPICAC XIV as a worm was to that wisest man.&lt;/p&gt;

&lt;p&gt;For the first time the Shah of Bratpuhr seemed really impressed, even startled. He hadn&#39;t thought much of EPICAC XIV&#39;s physical size, but the comparison of the worm and the wise man struck home. He looked about himself apprehensively, as though the tubes and meters on all sides were watching every move.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And so, the Shah of Bratphur decides to test the machine&#39;s capabilities, by asking a question...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The Shah turned to a glowing bank of EPICAC&#39;s tubes and cried in a piping singsong voice:&lt;/p&gt;

&lt;p&gt;Allakahi baku billa,&lt;/p&gt;

&lt;p&gt;Moumi a fella nam;&lt;/p&gt;

&lt;p&gt;Serani assu tilla,&lt;/p&gt;

&lt;p&gt;Touri serin a sam.&quot;&lt;/p&gt;

&lt;p&gt;&quot;The crazy bastard&#39;s talking to the machine,&quot; whispered Lynn.&lt;/p&gt;

&lt;p&gt;&quot;Ssssh!&quot; said Halyard, strangely moved by the scene.&lt;/p&gt;

&lt;p&gt;&quot;Siki?&quot; cried the Shah. He cocked his head, listening. &quot;Siki?&quot; The word echoed and died - lonely, lost.&lt;/p&gt;

&lt;p&gt;&quot;Mmmmmm,&quot; said EPICAC softly. &quot;Dit, dit. Mmmmm. Dit.&quot;&lt;/p&gt;

&lt;p&gt;The Shah sighed and stood, and shook his head sadly, terribly let down. &quot;Nibo,&quot; he murmured. &quot;Nibo.&quot;&lt;/p&gt;

&lt;p&gt;&quot;What&#39;s he say?&quot; said the President.&lt;/p&gt;

&lt;p&gt;&quot;&#39;Nibo&#39; - &#39;nothing.&#39; He asked the machine a question, and the machine didn&#39;t answer,&quot; said Halyard. &quot;Nibo.&quot;&lt;/p&gt;

&lt;p&gt;&quot;Nuttiest thing I ever heard of,&quot; said the President. &quot;You have to punch out the questions on that thingamajig, and the answers come out on tape from the whatchamacallits. You can&#39;t just talk to it.&quot; A doubt crossed his fine face. &quot;I mean, you can&#39;t, can you?&quot;&lt;/p&gt;

&lt;p&gt;&quot;No sir,&quot; said the chief engineer of the project. &quot;As you say, not without the thingamajigs and whatchamacallits.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It is almost irrelevant what question the Shah actually asked[1]. The problem here is that EPICAC XIV couldn&#39;t handle artibrary input. That&#39;s perfectly fine, because it wasn&#39;t designed to handle that input. It was, after all, built by fallible human beings (who didn&#39;t even anticipate that such input could be given).&lt;/p&gt;

&lt;p&gt;But the fact that flawed humans built EPICAC meant that EPICAC itself &lt;em&gt;is&lt;/em&gt; not perfect, and therefore flawed. Which again, is &lt;em&gt;perfectly fine&lt;/em&gt;. It was built to handle the problem of resource allocation...answering riddles from Shah is just not suited for its talents. You don&#39;t judge a fish by how fast it can climb trees.&lt;/p&gt;

&lt;p&gt;The problem is with the &lt;em&gt;humans&lt;/em&gt;. &lt;em&gt;They&lt;/em&gt; praised EPICAC as the &quot;greatest individual in history&quot;, of being &quot;dead right about everything&quot;, etc., etc. They glorified vaccum tubes for deciding how many refrigerators should be built for the next fiscal year. Resource allocation is a very important job, true, but the hype that humans have built around EPICAC is rather excessive. In fact, the hype so disgusted the Shah that he called EPICAC a &quot;baku&quot; (false god).&lt;/p&gt;

&lt;p&gt;This hype is bad for a very simple reason: it blinds humanity to any mistakes that EPICAC &lt;em&gt;can&lt;/em&gt; make. If you believe that EPICAC is very wise, then you will not seek to question EPICAC&#39;s choices. In fact, the humans don&#39;t even bother asking EPICAC &lt;em&gt;why&lt;/em&gt; it made the choices it did, making it hard to understand if the reasons for those choices were even valid to begin with. While EPICAC can be much better at resource allocation than humans, that does not mean that it will always make the right choice, every single time.&lt;/p&gt;

&lt;p&gt;And even if EPICAC make the right choices, it doesn&#39;t mean that the outcomes would be what we want. EPICAC&#39;s economic planning is unbiased, but it does have end-goals in mind, and those end-goals are reflected by EPICAC&#39;s programmers. The engineers believe in maxiziming the standard of living of the average citizen through economic growth and mass production of material goods. EPICAC has succeeded at this task admirably. However, EPICAC wasn&#39;t focused on making people &lt;em&gt;happy&lt;/em&gt;. It wasn&#39;t programmed to do that.&lt;/p&gt;

&lt;p&gt;Due to the proliferation of machine labor, the vast majority of humanity are unemployed in the United States...and &lt;em&gt;unemployable&lt;/em&gt;. EPICAC can bear some blame for this, due to EPICAC&#39;s strict enforcement of &quot;I.Q. and aptitude levels&quot; to seperate the wheat from the chaff, but most of the blame lies with its human collaborators who strongly supported technological progress, regardless of the social costs. Society has remained somewhat stable, due to the rise of &lt;a href=&quot;https://en.wikipedia.org/wiki/Make-work_job&quot;&gt;make-work jobs&lt;/a&gt; created by the Army and the Reconstruction and Reclamation Corps (funded by taxes on private enterprises), but the average citizen has nursed a grudge against the machinery that has taken away their dignity and sense of purpose. The Ghost Shirt Society, a radical terrorist group, sought to capitalize on the average citizen&#39;s greviances in their manifesto:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;Man has survived Armageddon in order to enter the Eden of eternal peace, only to discover that everything he had looked forward to enjoying there, pride, dignity, self-respect, work worth doing, has been condemned as unfit for human consumption.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Later on in the novel, the Ghost Shirt Society launched a nationwide uprising against machinery. The uprising successfully destroyed three American cities, and got very close to eliminating EPICAC itself. It&#39;s safe to say that mistakes were made.&lt;/p&gt;

&lt;p&gt;Could EPICAC and its human collaborators have prevented this disaster? Yes...but only if they had a different end-goal in mind: maximizing &quot;human dignity&quot; instead of mere &quot;standard of living&quot;. But while it might have stopped this specific uprising, EPICAC and its collaborators could have caused other problems as well. How would you measure human dignity, anyway? What sorts of trade-offs must be made in maximizing human dignity? Are these trade-offs that we are really prepared to make? Do we even &lt;em&gt;want&lt;/em&gt; to maximize human dignity, or do we instead want a balance between a variety of different, even contradictory goals? You could imagine a different terrorist group, the Adam Smith Society, writing a new manifesto and planning a new nationwide uprising:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;Man have survived Armageddon in order to enter the Eden of eternal dignity, only to discover that everything he had looked forward to enjoying there, wealth, freedom, economic growth, material goods worth owning, has been condemned as unfit for human consumption.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;At the end of the day, humans...&lt;em&gt;fallible&lt;/em&gt; humans...have to make choices when building their machines and delivering the data. EPICAC did nothing more than to carry out those choices to their logical, chilling conclusions. And EPICAC will not be able to please everyone. Sacrifices must be made.&lt;/p&gt;

&lt;p&gt;If we can&#39;t agree on how to fix the machine collaborator in this creative partnership, could we fix the humans collaborators instead? The human collaborators could acknowledge the possibility of machine error, and try their best to minimize the error. Rather than blindly trust the machine, the humans can evaluate the machine&#39;s advice, and decide whether to accept the advice, modify it to fit human whims, or decline it outright. Of course, this approach has its own faults. Humans are fallible, and it is possible that humans may unwisely reject the advice of a machine.&lt;/p&gt;

&lt;p&gt;In the real world, &lt;a href=&quot;http://www.govexec.com/excellence/promising-practices/2015/11/algorithms-make-better-hiring-decisions-humans/124035/&quot;&gt;an algorithm designed to hire employees did a much better job than managers who treated the algorithm as an advisory tool and used &quot;discretion&quot; to hire people&lt;/a&gt;, yet &lt;a href=&quot;http://www.huffingtonpost.com/mike-cassidy/centaur-chess-shows-power_b_6383606.html&quot;&gt;machine-human teams are able to win chess games more effectively than a standard human or a standard machine&lt;/a&gt; (though &lt;a href=&quot;http://marginalrevolution.com/marginalrevolution/2013/11/what-are-humans-still-good-for-the-turning-point-in-freestyle-chess-may-be-approaching.html&quot;&gt;this advantage is shrinking&lt;/a&gt;). Is the problem of &quot;resource allocation&quot; like hiring (in which case, it may still be better to blindly trust the machine, because the human is unable to add any value) or like chess (in which case, we do need humans at the helm ready to engage in collaboration)? Or are we willing to agree to a little bit of inefficiency because the consequences of too much efficiency may be too great?&lt;/p&gt;

&lt;p&gt;Obviously, EPICAC is just an idea in a science-fiction novel. But the broader questions EPICAC raises about human-machine collaboration are still relevant today. These are hard questions, but nobody ever said collaboration is ever easy. Human-machine collaboration is not a sure-fire way to victory or prosperity, nor should it be used as a mere buzzword to justify AI investment. There are many questions that a human collaborator has to wrest with greatly, and the odds of the human collaborator getting those questions wrong are high. The last thing today&#39;s human collaborators should do though is to behave like EPICAC&#39;s human collaborators -- to blindly trust the machine and to obey its every whim. To do so would  be to abdicate their responsibilites and to claim that humanity itself is obsolete.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;At no expense whatsoever to you,&quot; said Halyard, &quot;America will send engineers and managers, skilled in all fields, to study your resources, blueprint your modernization, get it started, test and classify your people, arrange credit, set up the machinery.&quot;&lt;/p&gt;

&lt;p&gt;The Shah shook his head wonderingly. &quot;Prakka-fut takki sihn,&quot; he said at last, &quot;souli, sakki EPICAC, siki Kanu pu?&quot;&lt;/p&gt;

&lt;p&gt;&quot;Shah says,&quot; said Khashdrahr, &quot; &#39;Before we take this first step, please, would you ask EPICAC what people are for?&#39; &quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;[1] If you are curious, the Shah asked a riddle to EPICAC. This is the translation of the riddle, as given by Khashdrahr.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;Silver bells shall light my way,
And nine times nine maidens fill my day,
And mountain lakes will sink from sight,
And tigers&#39; teeth will fill the night.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The answer to this riddle is posted in &lt;a href=&quot;https://www.reddit.com/r/riddles/comments/1tlbdk/silver_bells_shall_light_my_way_and_nine_times/&quot;&gt;this Reddit thread&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 15 Oct 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c24-player-piano.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c24-player-piano.html</guid>
        
        
      </item>
    
      <item>
        <title>T18 Novel Generation</title>
        <description>![CDATA[This month, I finished a blog post series about "text generation" -- or less jargony, programming computers how to write. This blog post series is available on the Practical Developer website (for mass consumption by a technical audience).
]</description>
        <content>&lt;p&gt;This month, I finished a blog post series about &quot;text generation&quot; -- or less jargony, programming computers how to write. This blog post series is available on the Practical Developer website (for mass consumption by a technical audience).&lt;/p&gt;

&lt;p&gt;Here are the links to those blog posts, in order of publication:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://dev.to/tra/structure-in-computer-generated-novels&quot;&gt;&quot;Structure&quot; in Computer-Generated Novels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://dev.to/tra/using-templates-innbspcomputer-generated-works&quot;&gt;Using Templates in Computer-Generated Works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://dev.to/tra/the-commonsense-knowledge-problem-in-computer-generated-works&quot;&gt;The &quot;Commonsense&quot; Problem in Computer-Generated Works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://dev.to/tra/who-are-the-audiences-of-computer-generated-novels&quot;&gt;Who are the Audiences of Computer-Generated Novels?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I started this series due to &lt;a href=&quot;tra38.github.io/c23-one-year-later.html&quot;&gt;my recent experiments in text-generation&lt;/a&gt;. I wanted to collect all the knowledge about that field so that other people wouldn&#39;t have to focus on reinventing the wheel.&lt;/p&gt;

&lt;p&gt;For example, &lt;a href=&quot;https://github.com/tra38/Prolefeed&quot;&gt;Prolefeed&lt;/a&gt; is a Ruby gem that was based on an algorithm that I invented in 2015. You give the algorithm pre-made content, and then the algorithm randomly shuffles its order. This algorithm was so simple that I wondered whether it was already invented.&lt;/p&gt;

&lt;p&gt;Well, it was. In 1986, Judy Malloy worked on &lt;a href=&quot;http://www.well.com/user/jmalloy/uncleroger/uncle.html&quot;&gt;&lt;em&gt;Uncle Rogers&lt;/em&gt;&lt;/a&gt;, an art project that also doubled as a computer program. One file in this project is called &lt;a href=&quot;http://www.well.com/user/jmalloy/uncleroger/188.html&quot;&gt;&quot;Terminals&quot;&lt;/a&gt; - the program would randomly select paragraphs from a &quot;corpus&quot; and then display them to the user[1]. Paragraph shuffling was &lt;a href=&quot;http://www.warriorforum.com/main-internet-marketing-discussion-forum/322057-their-tool-shuffles-paragraph-order.html&quot;&gt;also independently discovered and used in 2011&lt;/a&gt; to create spam articles that would trick Google into indexing their site and ranking them high in search rankings (an example of &quot;Black Hate SEO&quot;).&lt;/p&gt;

&lt;p&gt;There are probably other examples where random shuffling was &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiple_discovery&quot;&gt;independently discovered&lt;/a&gt;. The point is to stop this sort of &quot;multiple discovery&quot; from ever happening again. Text generation itself had a long history of academic research &lt;a href=&quot;http://wikis.sub.uni-hamburg.de/lhn/index.php/Story_Generator_Algorithms&quot;&gt;starting in the 1970s&lt;/a&gt;, and yet there has been a cycle where this technology is discovered, forgotten, rediscovered, reforgotten, etc., etc.&lt;/p&gt;

&lt;p&gt;It seemed more reasonable to document this technology so that users don&#39;t have to worry about writing brand new code that somebody already written 10 years ago. They could instead read these articles and learn from them, and then build off that knowledge to produce something brand new and innovative.&lt;/p&gt;

&lt;p&gt;However, by I started work on Article #4 in my series, I realized a flaw in my thinking. In my attempts to write about text generation, I realized that I was attempting to catalog the field...with all its nuances and quirks. Every attempt to add a new category only serves to reveal the flaws of my previous categorizations.&lt;/p&gt;

&lt;p&gt;For example, in Article #3, I wrote about the possibility of people treating computer-generated works as its own genre...with its own unique fanbase. While planning Article #4 though, I realized that there are &lt;em&gt;two&lt;/em&gt; unique fanbases for computer-generated works. The first fanbase loves computer-generated works for being a form of &quot;conceptual art&quot;, and the second fanbase likes the idea of consuming repetitive content. If there are two fanbases, are there &lt;em&gt;two&lt;/em&gt; different genres then? The clear idea I had in Article #3 was  undermined by details in Article #4.&lt;/p&gt;

&lt;p&gt;The Argentine writer Jorge Luis Borges wrote about my dilemma in the short story &lt;a href=&quot;http://www.alamut.com/subj/artiface/language/johnWilkins.html&quot;&gt;The Analytical Language of John Wilkins&lt;/a&gt;. John Wilkins wanted to create a language that would seek to explain the universe. But the problem with such a language is that the language&#39;s very construction would be arbitrary and based on cultural biases. There will always be &quot;ambiguities, redundancies and deficiencies&quot; in any attempt to categorize the universe, and such attempts at categorizations reveal more about the author than about the universe itself.&lt;/p&gt;

&lt;p&gt;Text generation is a field that is smaller than this universe. But it is still an extremely broad field, with its own hidden depth. Any attempt to fully cover the field would fail, and deciding what topics to cover and what topics to ignore is a very difficult (and rather arbitrary) choice. Rather than following in John Wilkins&#39; attempts to build the universal language, it would be better to simply end the blog series on a high-note.&lt;/p&gt;

&lt;p&gt;This is why writing about &quot;cutting-edge technologies&quot; such as text generation is so difficult. There is no way for a single human to fully explain the field coherently and objectively, no matter how many words he or she writes. What is left is a rather incomplete and biased picture of the world, not truly comprehensive or representative of the broader field. To truly understand the field and to avoid reinventing the wheel, you will likely have to do your own research into the field, learning from the biased viewpoints of others and trying to synthesize them together to create your own biased viewpoint.&lt;/p&gt;

&lt;p&gt;We are all &lt;a href=&quot;https://en.wikipedia.org/wiki/Blind_men_and_an_elephant&quot;&gt;blind men feebly trying to understand the elephant&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[1]The &quot;Terminals&quot; web app simulates randomly picking paragraphs from a corpus by having a blank keyboard that a user can click on, but if you are interested in a demonstration with no user interaction...please look at &lt;a href=&quot;http://www.well.com/user/jmalloy/uncleroger/Another_Party_in_Woodside.html&quot;&gt;Another Party In Woodside&lt;/a&gt; (a more recent program written by Judy Malloy).&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 29 Sep 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t18-novel-generation.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t18-novel-generation.html</guid>
        
        
      </item>
    
      <item>
        <title>C23 One Year Later</title>
        <description>![CDATA[Most people think spies are afraid of guns, or KGB guards, or barbed wire, but in point of fact the most dangerous thing they face is paper. Papers carry secrets. Papers can carry death warrants. Papers like this one, this folio with its blurry eighteen year old faked missile photographs and estimates of time/survivor curves and pervasive psychosis ratios, can give you nightmares, dragging you awake screaming in the middle of the night.---A Colder War
]</description>
        <content>&lt;blockquote&gt;&lt;p&gt;Most people think spies are afraid of guns, or KGB guards, or barbed wire, but in point of fact the most dangerous thing they face is paper. Papers carry secrets. Papers can carry death warrants. Papers like this one, this folio with its blurry eighteen year old faked missile photographs and estimates of time/survivor curves and pervasive psychosis ratios, can give you nightmares, dragging you awake screaming in the middle of the night.---&lt;a href=&quot;http://www.infinityplus.co.uk/stories/colderwar.htm&quot;&gt;A Colder War&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Humans have written papers all their lives. Writing was once considered a praiseworthy activity that required intelligence.  But technology has now advanced to the point that computers are able to imitate the very process of writing successfully, and we are forced to decide between two unappeasing statements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Computers must be intelligent.&lt;/li&gt;
&lt;li&gt;Writing doesn&#39;t require intelligence.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is, to me, pretty scary for a variety of reasons: loss of purpose and ego issues, possible rise in unemployment, human dependency on technology to do all the work for them, etc. And I wanted to do something to counter the rising power of AI.&lt;/p&gt;

&lt;p&gt;It has been 15 months since I first entered DBC, almost one year since I graduated from Dev Bootcamp. During that time, I attempted to research the emerging field of computer-generated literature...in the hopes of using this technology against them, as a form of advocacy against uncontrolled research into AI.&lt;/p&gt;

&lt;p&gt;During the on-site portion of the DBC curriculum in Chicago, many people learned about this plan, especially after I produced &lt;a href=&quot;https://github.com/tra38/FriendComputer&quot;&gt;Friend Computer&lt;/a&gt;, a blog written by a computer, as a standalone DBC project. However, since then, I have not been in much contact with the people on DBC ever since my graduation...and so I decide to write a blog post to explain what happened.&lt;/p&gt;

&lt;p&gt;I&#39;ll start by quoting an email that I sent to a random stranger:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Let me introduce myself fairly carefully. I like to write. When I was a teenager, I served as a volunteer journalist. In college, I published a research paper. Even today, I write nonfictional blog posts and some (unpublished) fictional stories. So I still write, although I do not identify myself as a &quot;writer&quot;. My day-job is a computer programmer...where I write computer code (although it may not be beautiful or elegant to read).&lt;/p&gt;

&lt;p&gt;I had very some uncomfortable feelings about artificial intelligence and technology...especially our overt dependence on it and its potential impact on humanity. After reading an article about Narrative Science and its robojournalist articles, I wanted to take a stand against technological progress causing us to &quot;shoot ourselves in the foot&quot; [by writing a dystopian novel about an AI supercomputer that ruled over human society with an iron fist].&lt;/p&gt;

&lt;p&gt;And I immediately realized that this novel had to be computer-generated. It had to be that way. If I &quot;handwrote&quot; a sci-fi novel about the dangers of technology, then it would just be my opinions, my thoughts. Not reality. Nobody would listen to the thoughts of a random person, and would simply dismiss my fear as &quot;Luddism&quot;. If I am able to build proof of the dangers of technology (computer-generated literature), then that would make my arguments against technology more persuasive. &quot;If technology can do X now, what about the future?&quot; Etc., etc.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The &quot;Ozymandias Gambit&quot; is the term that Duke Greene (a DBC teacher) named my scheme. It is named after the character from the &quot;Watchmen&quot; comic book series. Ozymandias, the main villian of the comic book series, wanted to end the Cold War by creating a Lovecraftian monster to attack both the United States and the Soviet Union. His hope is that this monster would scare the superpowers long enough to unify together, thereby forestalling the possibility of nuclear armageddon.&lt;/p&gt;

&lt;p&gt;I built &lt;a href=&quot;https://github.com/tra38/Skynet&quot;&gt;&quot;Skynet&quot;&lt;/a&gt;, a command-line program that can be used to generate stories based on a &quot;Mad-Lib&quot;-style template. Someone even built &lt;a href=&quot;https://github.com/enkiv2/Skynet/blob/master/txt2sky.py&quot;&gt;a Python script&lt;/a&gt; that can turn existing novels &lt;em&gt;into&lt;/em&gt; templates that can then be used to generate stories...and used it and &lt;a href=&quot;https://github.com/enkiv2/Skynet/blob/master/odyssey.dict&quot;&gt;a configuration file&lt;/a&gt; to generate a Sky template of &lt;a href=&quot;https://github.com/enkiv2/Skynet/blob/master/odyssey.sky&quot;&gt;The Odyssey&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, certainly, I could have actually produced the anti-technological novel with this tool I had. But I would have to &lt;em&gt;write&lt;/em&gt; out all the templates in question, which almost defeats the whole purpose of building the program. The templates would have done most of the work, while the computer in question really only randomly select words to plug into the templates. So I gave up on that line...and tried other approaches to procedural generation.&lt;/p&gt;

&lt;p&gt;As for expressing my ire about technology, I did find other outlets. I wrote algorithms to generate &lt;a href=&quot;https://medium.com/laughter-in-the-singularity&quot;&gt;two short stories against technology&lt;/a&gt; and &lt;a href=&quot;tra38.github.io/blog/ai3.html&quot;&gt;a blog post condemning artificial intelligence&lt;/a&gt;. There was still some human involvement involved. I wrote all the words in the short stories and the blog posts. But the algorithm also played a role in deciding the order of my paragraphs within the story. And the order matters just as much as the text. I even released my algorithm as an open-source Ruby gem called &lt;a href=&quot;https://github.com/tra38/Prolefeed&quot;&gt;Prolefeed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, yeah, I carried out a lesser version of the &quot;Ozymandias Gambit&quot;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Most people didn&#39;t care.&lt;/em&gt; Those that did can be placed into two camps, the Futurists and the Traditionalists:&lt;/p&gt;

&lt;h2&gt;The Futurists&lt;/h2&gt;

&lt;p&gt;There are those who really liked the technology that I was working on. They saw it as cool and exciting, and thought about improving on my methods. Which, of course, &lt;em&gt;misses the point.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Which is why I started my blog post by quoting from &quot;A Colder War&quot; instead of from the &quot;Watchmen&quot;. &quot;A Colder War&quot; is a novella that had a premise: What if the superpowers discovered Lovecraftian technologies? The answer was simple...they started using it to fight their Cold War! The &#39;paper&#39; that the quote was referring to is a CIA report about Soviet Union&#39;s &quot;Project Koschei&quot; (a plan to use Cthulhu as a superweapon against the United States).&lt;/p&gt;

&lt;p&gt;So Ozymandias may have been too optimistic. Instead of seeing Ozymandias&#39; monster as a wakeup call, the superpowers could have simply started building their own monsters instead. I mean, Ozy already did it. How hard could it be?&lt;/p&gt;

&lt;p&gt;Ozymandias could, of course, take a perverse pride in contributing to the very fear that he opposed. In fact, he&#39;d probably make a killing selling his monster-building techniques to the superpowers. But the irony is there. It cannot be concealed or denied.&lt;/p&gt;

&lt;h2&gt;The Traditionalists&lt;/h2&gt;

&lt;p&gt;These people did view technology as a threat, and thus would sympathize with my anti-tech rants. They were mostly creeped out by the possibility of text generation. The computer-generated text may not be &#39;on par&#39; with human-generated work, but it could improve with time..and besides, computer-generated work doesn&#39;t have to be &quot;good&quot;. It just have to be &quot;good enough&quot;. This audience was receptive to my message.&lt;/p&gt;

&lt;p&gt;But that&#39;s it. Having felt chills down their spine, they haven&#39;t moved a single inch to stop this trend. It&#39;s almost as if they couldn&#39;t &lt;em&gt;do anything&lt;/em&gt; to stop it. There is almost a sense of resignation...that you can&#39;t fight progress. I guess the best you can do is write against the future...but then again, I already wrote an algorithm to write against the future.&lt;/p&gt;

&lt;p&gt;In this scenario, people saw Ozymandias&#39; evil monster, but resigned themselves to the fact that it existed and moved on with their lives. &quot;Yeah, a monster destroyed New York. What a shame. So whose going to win the Super Bowl this year?&quot; It&#39;s not like they hate the future...they certainly do. But they realize that they can&#39;t change it. All they can do is to accept it and prepare for it.&lt;/p&gt;

&lt;h2&gt;The Failure of the Ozymandias Gambit&lt;/h2&gt;

&lt;p&gt;Today, I sometimes &quot;write&quot; computer-generated blog posts about computer-generated literature and &lt;a href=&quot;https://dev.to/tra&quot;&gt;post them on dev.to&lt;/a&gt;, with plans to eventually port them over to this site. I like to inform people about this field and its technical merits, while also conveying my distaste and disgust. at the field as well.&lt;/p&gt;

&lt;p&gt;This blog post, however, was not computer-generated. I could have wrote an algorithm to write this blog post. I have to break this blog post up into smaller chunks, and then use &lt;a href=&quot;https://github.com/tra38/Prolefeed&quot;&gt;Prolefeed&lt;/a&gt; to shuffle the chunks. It is fairly easy (although time-consuming) to pull off. But today, I just wanted to express &lt;em&gt;my&lt;/em&gt; own feelings about my experience. Not what the computer wanted to write about. Maybe the computer might be a better writer than me. But I still want to vent my thoughts anyway. (Duke Greene, my DBC teacher, have also said the same thing about his own creative works...he likes doing them manually because he wants to express his own thoughts, without any such mechanical filters.)&lt;/p&gt;

&lt;p&gt;I&#39;ll probably keep writing against the future, warning people about the possible disaster of artificial intelligence and how we need societal regulation against it to limit its damages. But now I am under no illusion that my posts will actually change anything. At least I tried.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 23 Jul 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c23-one-year-later.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c23-one-year-later.html</guid>
        
        
      </item>
    
      <item>
        <title>T17 Markov</title>
        <description>![CDATA[According to Victor Powell, "Markov chains, named after Andrey Markov, are mathematical systems that hop from one "state" (a situation or set of values) to another." Many people have used Markov chains to generate literature based on a pre-existing corpus. This blog post explains some experiments I recently did with Markov chains, with the goal of generating readable text.
]</description>
        <content>&lt;p&gt;According to &lt;a href=&quot;http://setosa.io/ev/markov-chains/&quot;&gt;Victor Powell&lt;/a&gt;, &quot;Markov chains, named after Andrey Markov, are mathematical systems that hop from one &quot;state&quot; (a situation or set of values) to another.&quot; Many people have used Markov chains to generate literature based on a pre-existing corpus. This blog post explains some experiments I recently did with Markov chains, with the goal of generating readable text.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zolrath/marky_markov&quot;&gt;Marky_Markov&lt;/a&gt; is a Ruby gem that can be used to generate Markov chains. I used it to quickly set up a Markov chain and start fooling around with it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;ruby&quot;&gt;require &#39;marky_markov&#39;

markov = MarkyMarkov::TemporaryDictionary.new
markov.parse_string &quot;The cat is very friendly.&quot;
markov.parse_string &quot;The dog is slightly friendly.&quot;
markov.parse_string &quot;The sky is very unfriendly.&quot;
markov.parse_string &quot;The window is slightly unfriendly.&quot;

markov.generate_10_sentences
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;=&gt;&quot;The window is slightly unfriendly. The window is slightly friendly. The sky is very unfriendly. The sky is very unfriendly. The window is slightly friendly. The sky is very friendly. The cat is very unfriendly. The cat is very unfriendly. The window is slightly unfriendly. The cat is very friendly.&quot;&lt;/p&gt;

&lt;p&gt;Some of the sentences are copies of the original corpus, but other sentences are original! The algorithm had learned how to write original sentences!&lt;/p&gt;

&lt;p&gt;These sentences are fairly dull though. The generator also repeats itself sometimes.&lt;/p&gt;

&lt;p&gt;At this point, the budding Markov Chainer will start searching for a pre-made corpus that can then be fed into the Markov Chain. But I&#39;m not a budding Markov Chainer...if anything, I&#39;m slightly jaded. The benefit of feeding a pre-made corpus into a Markov Chain is that the text start sounding more interesting. The problem is that the text also becomes less &lt;em&gt;coherent&lt;/em&gt;. Here&#39;s &lt;a href=&quot;https://brandonbyars.com/2007/05/06/tdding-a-markov-chain/&quot;&gt;some sample text from a Markov chain trained on &quot;The Raven&quot;&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Once upon a bust of Pallas just above my chamber door; –
This it is, and this mystery explore; –
‘Tis the wind and nothing more.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I can understand why some people may be happy with text that seems meaningful so long as you don&#39;t read it too deeply. In fact, this text could plausibly be used as poetry. Any oddities in the text itself can be explained away as stylistic choices and metaphors.&lt;/p&gt;

&lt;p&gt;But if we decide to use Markov chains outside of poetry, well...um....&lt;/p&gt;

&lt;p&gt;Here&#39;s &lt;a href=&quot;http://www.r-bloggers.com/is-deep-learning-a-markov-chain-in-disguise/&quot;&gt;some sample text from a Markov chain trained on the &#39;tinyshakespeare&#39; corpus&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;DUKE VINCENTIO:&lt;/p&gt;

&lt;p&gt;Well, your wit is in the care of side and that.&lt;/p&gt;

&lt;p&gt;FRIAR LAURENCE:&lt;/p&gt;

&lt;p&gt;Or walk liest;&lt;/p&gt;

&lt;p&gt;And the ears.&lt;/p&gt;

&lt;p&gt;And hell!&lt;/p&gt;

&lt;p&gt;In self.&lt;/p&gt;

&lt;p&gt;PETRUCHIO:&lt;/p&gt;

&lt;p&gt;Persuading to our the enemy, even woman, I&#39;ll afford show&#39;d and speaking of&lt;/p&gt;

&lt;p&gt;England all out what least. Be satisfied! Now, sir.&lt;/p&gt;

&lt;p&gt;Second Lord:&lt;/p&gt;

&lt;p&gt;They would be ruled after this chamber, and&lt;/p&gt;

&lt;p&gt;my fair nues begun out of the fact, to be conveyed,&lt;/p&gt;

&lt;p&gt;Whose noble souls I&#39;ll have the heart of the wars.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;...yeah, no. The blogger is surprised about how his Markov chain learned Old English, but I absolutely hate this output. This is why I had been reluctant to use Markov chains ever...because what they actually produce is utter nonsense.&lt;/p&gt;

&lt;p&gt;When I conduct experimentation in text generation, my goal is to produce text that reaches human quality. This bias may have been caused by my previous experience as a journalist, where I was expected to write words that people are able to read...not necessarily text that &lt;em&gt;appears&lt;/em&gt; to be readable. This causes me to prefer more &#39;conservative&#39; techniques in text generation (shuffling paragraphs, using pre-written templates, etc.)&lt;/p&gt;

&lt;p&gt;Recently, I started &lt;a href=&quot;https://medium.com/laughter-in-the-singularity&quot;&gt;a Medium blog&lt;/a&gt; where I showed off some fictional work that was computer-generated. This blog was somewhat controversial on Reddit, as can be seen in &lt;a href=&quot;https://www.reddit.com/r/proceduralgeneration/comments/4ken1d/laughter_in_the_singularity_computergenerated/?&quot;&gt;the comment thread&lt;/a&gt;. Many people raised the valid point that the algorithms used were just too simplistic for their tastes (as I was too reliant on my &#39;conservative&#39; techniques). While I was happy with my output (it was readable), I also realized that I needed to do slightly more experimentation. One reddit poster (kleer001) made a rather interesting comment:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;let&#39;s see some markov chains maybe?
here, have som fun with this: http://projects.haykranen.nl/markov/demo/
sorry I noped you, you sound like a cool dude, but still, you can do hella better. i believe in you.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hence, why I was fooling around with marky_markov.&lt;/p&gt;

&lt;p&gt;Looking at the output of my toy Markov chain (&quot;The window is slightly friendly&quot;) makes me realize that the main problem I had with Markov chains isn&#39;t necessarily the chain itself, but the corpus that people use to train on it. If you provide complicated prose to a Markov chain (such as Shakespeare&#39;s plays), you are not going to get good results out of it. What I&#39;m going to have to do is to simplify the prose to a level that a Markov chain will be able to grasp and imitate properly.&lt;/p&gt;

&lt;p&gt;I need to generate a corpus that follow these two rules:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Each sentence should have very simplistic and repetitive grammar.&lt;/li&gt;
&lt;li&gt;Each sentence should be context-less; there should be no connection to previous and future sentences (the Markov chain will not have the ability to understand the context of words).&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Now, writing out all these sentences for a corpus is rather dull...which can explain why some people reach for a pre-made corpus instead. But I remembered that I still had prior experience in text-generation. Why don&#39;t I write a program that can generate text...and then use its &lt;em&gt;output&lt;/em&gt; as a corpus? I used the Ruby gem &lt;a href=&quot;https://github.com/maetl/calyx&quot;&gt;&#39;Calyx&#39;&lt;/a&gt; to quickly set up a template-based text generator.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require &#39;marky_markov&#39;
require &#39;calyx&#39;

markov = MarkyMarkov::TemporaryDictionary.new

class CorpusGenerator &amp;lt; Calyx::Grammar
  start &#39;{dialogue}, {gender} {speak} {mood}.&#39;
  rule :dialogue, &#39;Do you think she is out there&#39;, &#39;Do you think she cares&#39;, &#39;Will she ever care&#39;,
  &#39;We have a job to do&#39;, &#39;She has a job to do&#39;, &#39;I did the right thing&#39;,
  &#39;She did what was right&#39;, &#39;Do not kill me&#39;, &#39;I must kill you&#39;,
  &#39;You have a job to do&#39;, &#39;I am sorry&#39;, &#39;She is sorry&#39;,
  &#39;I hate you&#39;, &#39;I am sorry I met you&#39;
  rule :gender, &#39;he&#39;, &#39;she&#39;, &#39;the computer&#39;, &#39;the monster&#39;
  rule :speak, &quot;says&quot;, &quot;giggles&quot;, &quot;laughs&quot;, &quot;cries&quot;, &quot;sings&quot;
  rule :mood, &quot;sadly&quot;, &quot;madly&quot;
end

generator = CorpusGenerator.new

corpus = []

10.times do
  sentence = generator.generate
  corpus &amp;lt;&amp;lt; sentence
  markov.parse_string sentence
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, the problem is that the sentences are so basic that it&#39;s likely a Markov chain could just re-generate those same, basic sentences. That&#39;s no fun. But, the Markov chain does have the possibility of generating unique sentences too. I may need to measure how many &#39;duplicated&#39; sentences it generates, to determine how much &quot;uniqueness&quot; the Markov chain can produce.&lt;/p&gt;

&lt;p&gt;I decide to run my program with 10 corpus sentences, and then generate 10 sentences using my Markov chain, and then compare the uniqueness (the number of unique sentences divided by the number of total sentences generated).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SAMPLE = 10

SAMPLE.times do |sentence|
  generated_sentences &amp;lt;&amp;lt; markov.generate_1_sentence
end

duplicated_sentences = generated_sentences.select {|sentence| corpus.include?(sentence) }

def calculate_odds(duplicated_sentences)
  duplicates = (duplicated_sentences.length.to_f)
  percent_of_duplicate = (duplicates/(SAMPLE.to_f))
  1 - percent_of_duplicate
end

puts &quot;The number of duplicated sentences is #{duplicated_sentences.length}.&quot;
puts &quot;The uniqueness of the text is #{calculate_odds(duplicated_sentences)}.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also added some print statements to this code to view the original corpus and the generated sentences. I highlighted any unique sentences by using dashes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Input Corpus (Generated By Templates):
Do you think she cares, the monster says madly.
Do you think she cares, the monster sings madly.
She has a job to do, she giggles madly.
I am sorry, she sings sadly.
I am sorry I met you, the computer cries sadly.
I hate you, he says sadly.
I did the right thing, she laughs madly.
I am sorry I met you, she sings madly.
She has a job to do, the monster says sadly.
Will she ever care, the monster says madly.

#Ouput Sentences (Generated by Markov Chains):
I hate you, he says sadly.
I did the right thing, she laughs madly.
Will she ever care, the monster says madly.
She has a job to do, she giggles madly.
I hate you, he says sadly.
- I am sorry I met you, she sings sadly. -
She has a job to do, she giggles madly.
- Will she ever care, the monster says sadly. -
- Will she ever care, the monster sings madly. -
Will she ever care, the monster says madly.

The number of duplicated sentences is 7.
The uniqueness of the text is 0.19999999999999996.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, about 20% of the generated text is unique. That&#39;s...actually kinda justifiable. Surely, the corpus generator is doing most of the work, but the Markov chain is able to add some additional &quot;variation&quot; to the output.&lt;/p&gt;

&lt;p&gt;Usually, Markov chains work well when you give it a large corpus. But luckily, since we already have a corpus text generator, we can just tell it to produce as many sentences as we want. So, I generate a corpus of 1000 sentences, use that corpus to train a Markov chain, and then use the Markov chain to generate 1000 new sentences.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The number of duplicated sentences is 712.
The uniqueness of the text is 0.28800000000000003.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Excellent. 288 unique sentences! I wonder what they read like...&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;I met you, the monster giggles madly.
a job to do, she sings madly.
I met you, she cries madly.
must kill you, she sings madly.
do, the monster laughs sadly.
You have a job to do, the computer laughs sadly.
he cries madly.
job to do, the computer cries madly.
a job to do, she sings madly.
me, he giggles madly.
I met you, the monster cries madly.
you think she is out there, she says madly.
he says madly.
She is sorry, the monster cries sadly.
she cries madly.
I met you, the monster laughs sadly.
right, she laughs sadly.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oh.&lt;/p&gt;

&lt;p&gt;Clearly, there&#39;s still work to be done, especially with the initial text generator. The sentence fragments are annoying (though I presume I can write some more code to scan the generated text and delete any sentence that aren&#39;t complete). The bigger problem is that this wall of text is...fairly dull and boring. I don&#39;t really care why all these characters are speaking.&lt;/p&gt;

&lt;p&gt;I need to try to create a somewhat sensible theme, at least one well enough that to justify having all these random people talking to each other. Or maybe I need to have different types of sentences that could be generated (possible descriptions and actions) that makes the generated text slightly more engaging.&lt;/p&gt;

&lt;p&gt;The Markov chain interestingly was able to generate a phrase that was not specifically hardocded into the generator...&quot;I met you&quot; (obviously an extract from &quot;I am sorry I met you&quot;). And yes, it can repeat that phrase a lot.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;I met you, the monster says sadly.
I met you, the computer giggles madly.
I met you, the monster says sadly.
I met you, the computer laughs madly.
I met you, the monster sings madly.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am unsure whether this experiment was a success. On the one hand, the Markov chain did add &#39;value&#39; to the process, by generating fairly unique sentences. On the other hand, much of this additional variation could have been easily accomplished by simply running the text generator again. The variations that the Markov chain does produce are fairly trivial and may not be interesting on its own.&lt;/p&gt;

&lt;p&gt;I am also dubious on whether more uniqueness would actually be a worthwhile goal. &lt;a href=&quot;http://procedural-generation.tumblr.com/post/137167846082/infinity-and-procedural-generation-i-was-asked-on&quot;&gt;Infinite text generation itself may not be very interesting&lt;/a&gt;. You&#39;re usually only going to read a small fraction of whatever the program generates, before you get bored and ready to move onto the next content to consume. If that&#39;s the case, then why try to increase the number of possible variations? The reader is still going to get bored anyway. It may be smarter to instead focus on making each individual variation interesting.&lt;/p&gt;

&lt;p&gt;The one bright spot in this research is its possible application to machine learning. The blogger who trained Markov chains on the &#39;tinyshakespeare&#39; corpus asked &lt;a href=&quot;http://www.r-bloggers.com/is-deep-learning-a-markov-chain-in-disguise&quot;&gt;&quot;Is Deep Learning a Markov Chain In Disguise?&quot;&lt;/a&gt; The output of a machine learning algorithm (when trained on text) is only slightly better than that of a Markov chain, after all. If you can write a program that can generate a corpus that then can train a Markov chain to produce meaningful text, then you could reuse that same program on a machine learning algorithm. Maybe their output may be more interesting to read.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 18 Jun 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t17-markov.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t17-markov.html</guid>
        
        
      </item>
    
      <item>
        <title>T16 Resume Driven Development</title>
        <description>![CDATA[Disclaimer: I wrote the book "Essential Copying and Pasting From Stack Overflow", which was inspired by a cover designed by ThePracticalDev. This blog post is also inspired by a cover designed by ThePracticalDev. Just like "Essential Copying and Pasting From Stack Overflow", "Expert Resumé Driven Development" is also written in a deadpan manner.
]</description>
        <content>&lt;p&gt;Disclaimer: I wrote the book &lt;a href=&quot;https://tra38.gitbooks.io/essential-copying-and-pasting-from-stack-overflow/content/&quot;&gt;&quot;Essential Copying and Pasting From Stack Overflow&quot;&lt;/a&gt;, which was inspired by a cover designed by &lt;a href=&quot;https://twitter.com/thepracticaldev?lang=en&quot;&gt;ThePracticalDev&lt;/a&gt;. This blog post is also inspired by a cover designed by ThePracticalDev. Just like &quot;Essential Copying and Pasting From Stack Overflow&quot;, &quot;Expert Resumé Driven Development&quot; is also written in a deadpan manner.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float: left; height: 30%; width: 30%&quot; src=&quot;http://i.imgur.com/DQcks8u.jpg&quot; alt=&quot;Cover for Resumé Driven Development, &#39;The Passionate, Functional, Micro-Serviced Approach&quot;&gt;&lt;h3&gt;What is &quot;Resumé Driven Development&quot;?&lt;/h3&gt;&lt;/p&gt;

&lt;p&gt;Resumé Driven Development refers to the practice of choosing hot new technologies for your projects to make your resumé more impressive. For example, you want to write a program in that hot new Javascript micro-generator framework &lt;a href=&quot;https://github.com/amwmedia/plop&quot;&gt;&quot;Plop.js&quot;&lt;/a&gt;...because it&#39;s a hot new JavaScript framework. Sure, you can use the technologies that you already know and are probably better suited for the job, but that wouldn&#39;t be as impressive as riding the hot bandwagon. You don&#39;t even know what &quot;Plop.js&quot; is, but you&#39;ll find out soon enough.&lt;/p&gt;

&lt;p&gt;There is some controversy on whether Resumé Driven Development is actually good. &lt;a href=&quot;http://willcode4beer.com/opinion.jsp?set=in_favor_of_rdd&quot;&gt;Paul E. Davis defended the practice&lt;/a&gt; as it is an indictator that the developer is willing to learn new technologes instead of sticking with potentially obsolete solutions. Sure, &quot;Plop.js&quot; may not actually be suited for your use case, but at least you showed that you &lt;em&gt;can&lt;/em&gt; learn it and use it quickly, and that you could later on find the bleeding-edge technology that might actually be useful.&lt;/p&gt;

&lt;p&gt;&quot;In the end, if developers are not concerned with their own careers, it&#39;s not likely they&#39;ll be concered with your business.&quot;---Paul E. Davis&lt;/p&gt;

&lt;p&gt;Most developers seem to detest RDD though (as can be seen by &lt;a href=&quot;http://rdd.io&quot;&gt;this parody website&lt;/a&gt;). There is a general belief that developers are not using using the hot new technologies in their spare time, but instead &lt;a href=&quot;http://www.healthcareguy.com/2007/01/19/resume-driven-development-rdd/&quot;&gt;using them on company projects&lt;/a&gt;. This is a colossal waste of company funds, as the technology may be ill-suited for the task at hand and can lead to long-term maintanance headaches.&lt;/p&gt;

&lt;p&gt;Developers are not the only people that engage in Resumé Driven Development. Management may also engage in RDD &lt;a href=&quot;http://radar.oreilly.com/2014/10/resume-driven-development.html&quot;&gt;during the hiring process as well&lt;/a&gt;. If a job vacancy exists, there is a desire to hire a new programmer with the same skillset of the old programmer. So the old programmer was an expert in Plop.js, then the job posting will read &quot;6 months  experience with Plop.js&quot;. This may be a very bad thing because you are optimizing for knowledge of certain technologies, instead of choosing the &quot;right tool&quot; for the job. If you only hire Plop.js developers, you will only get Plop.js websites.&lt;/p&gt;

&lt;p&gt;RDD is probably a subset of a larger &lt;a href=&quot;https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem&quot;&gt;Principal-Agent Problem&lt;/a&gt;. The Principal (management) hires an Agent (a developer) to build a program and allow the Agent to choose the tech stack. But the Agent&#39;s interest (making his resumé more impressive) can be orthogonal to the Principal&#39;s interest (producing a great product by using the &quot;right tool&quot; for the job). If the Principal allows the Agent to do as he wish, then the Agent &lt;strong&gt;will&lt;/strong&gt; do as he wishes, thereby leading to the Agent to prosper and the Principal to suffer.&lt;/p&gt;

&lt;p&gt;RDD is composed of two sections: the Resumé and the Technology. Let&#39;s look at them both briefly.&lt;/p&gt;

&lt;h3&gt;The Role of the &quot;Resumé&quot;&lt;/h3&gt;


&lt;p&gt;A resumé serves to let people know what you have done, in the hopes of getting people impressed. According to &lt;a href=&quot;http://cdn.theladders.net/static/images/basicSite/pdfs/TheLadders-EyeTracking-StudyC2.pdf&quot;&gt;a study by TheLadders, a resume re-writing company&lt;/a&gt;, recruiters can spend 6 seconds per  resumé, scanning for keywords and cursory background information about your education and job history before deciding whether you are &quot;fit&quot; or &quot;no-fit&quot;. You can see why some developers want to maximize those 6 seconds by practicing RDD.&lt;/p&gt;

&lt;p&gt;Now, there is not that much in-depth examination of what&#39;s on the resumé. If someone says that they used Plop.js when building a Uber-For-Dogs application, then you assume that they did use Plop.js and that there actually is a Uber-For-Dogs application...that he really spent 6 months on it...and that he got to pet a unicorn while on the job. It says so on the resumé. Just keep scanning for more keywords then.&lt;/p&gt;

&lt;p&gt;You can see where I&#39;m going here. Resumés can lie. You can claim to have worked on sixty Plop.js projects in closed-source companies, and provide fake phone numbers and references as &#39;proof&#39; that these closed-source projects exist. Lying is horribly unethical, and I would not recommend it for anyone to do. But it can be done, and is probably more efficent than a pure RDD approach...at least in getting the foot in the door. However, at the interview stage, interviewers will attempt to weed out those that did lie on their resumés - such as asking basic questions like &quot;What is Plop.js?&quot;.&lt;/p&gt;

&lt;p&gt;So the better option is to actually use the technologies on real projects then, so that when you get to the interview stage, you can actually prove your expertise in it and not be exposed as a fraud. That (sadly) means you do have to build a Uber-For-Dogs application just so you can use the Plop.js keyword. You may even need to provide a link to the application and show the source code, in case someone looks at your resumé for longer than six seconds. However, once you do this, you do not have to worry about proving anything else. If you can demonstrate that you can use Plop.js, then most people will assume that you know how to use it.&lt;/p&gt;

&lt;h3&gt;Choosing the Hot Technology&lt;/h3&gt;


&lt;p&gt;The biggest problem with choosing hot new technologies isn&#39;t actually learning them. It&#39;s difficult, and you&#39;ll have to deal with bad documentation and difficult solutions, but given enough time and persistence, you will eventually succeed.&lt;/p&gt;

&lt;p&gt;No, the biggest problem with choosing hot new technologies is that you don&#39;t &lt;strong&gt;know&lt;/strong&gt; what is actually hot.&lt;/p&gt;

&lt;p&gt;You can guess. You can listen to a community, and if the community talks a lot about Plop.js, then that suggest that Plop.js is hot. If the community stops talking about Plop.js, then Plop.js must not be hot. You can bookmark &lt;a href=&quot;https://www.google.com/trends/&quot;&gt;Google Trends&lt;/a&gt; and pay attention to what words people are searching. You can look at job postings and see what keywords the recruiters are using. And so on and so forth.&lt;/p&gt;

&lt;p&gt;But they&#39;re all trailing indictators. It doesn&#39;t help you predict whether that tech will stay hot in the future.&lt;/p&gt;

&lt;p&gt;It is here that Gartner Hype Cycle can be most useful for an RDDer. Gartner argues that all new technologies go through a cycle. I described the Hype Cycle in &lt;a href=&quot;http://tra38.github.io/blog/ai3.html&quot;&gt;my blog post against Artifical Intelligence&lt;/a&gt;...and I reprint my comments on this cycle here:&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float: right;&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Gartner_Hype_Cycle.svg/559px-Gartner_Hype_Cycle.svg.png&quot; &gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;At first, people become very interested in a brand new technology (a &quot;Technology Trigger&quot;). Companies start to over-invest in researching this technology, leading to a &quot;Peak of Inflated Expectations&quot; (i.e, a bubble). But the technology turns out to have major limitations. As a result, investment in the technology dries up (&quot;Trough of Disillusionment&quot;). Most companies either begin laying people off or closing down outright.&lt;/p&gt;

&lt;p&gt;Eventually, the survivors soon realize how to use the technology properly (&quot;Slope of Enlightenment&quot;), and we can finally use the technology in our day-to-day life (&quot;Plateau of Productivity&quot;). But as this picture from Wikipedia shows, the visibility of the technology in the Plateau of Productivity is much less than the visibility of that same technology in the Peak of Inflated Expectations. The brand new technology has done great things for us. It&#39;s just not as great as we hoped it to be. And does it justify the extreme waste seen in the &quot;Peak of Inflated Expectations&quot;?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Since the technology reaches the maximum visibility/hype in the Peak of Inflated Expectations, this implies that, by the time you hear of a tech, &lt;em&gt;it&#39;s already too late&lt;/em&gt;. The only people who would be able to take advantage of the hype are the &#39;early adopters&#39;, and they are the ones who will likely reap most of the benefits (though they also accept most of the costs as well, since not all new technologies are interesting or useful enough to go through this Hype Cycle).&lt;/p&gt;

&lt;p&gt;Another message this charts tells us is that the best time to learn a new technology is either during the Technology Trigger or the Trough of Disillusionment.&lt;/p&gt;

&lt;p&gt;During the Technology Trigger stage, there are no experts. There are only a few people who know your keyword. Specializing now as an &#39;early adopter&#39; (while the field is still young) would be much more impressive than being an expert during the Peak of Expectation, when you have thousands of &#39;experts&#39; in your field. Building a bot that can draw paintings now seems neat. Building a paint-bot five years from now, when every programmer have already built their own personal paint-bot? &lt;strong&gt;Boring.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;During the Trough of Disillusionment, you are able to take advantage of previous research done during the Technology Trigger and the Peak of Inflated Expectations, learning from past successes and failures with the tech. You also will have less competition during the Trough, as most programmers have already left to move onto the next &quot;hot&quot; technology. Eventually, interest in the tech will revive, and your lovely keyword will regain some allure.&lt;/p&gt;

&lt;p&gt;Any other time to study a technology would carry either too much competition (the Peak of Inflated Expectations) or too little reward (the Plateau of Productivity) to justify the expense. The only reason you would want to study the technology in that case is because you think it might actually help you grow as a developer.&lt;/p&gt;

&lt;!-- Now, if you are not dealing with recruiters but instead cold-calling or networking with companies directly, then it is possible that a company will probably do more in-depth research on you before deciding &quot;fit&quot;/&quot;no-fit&quot;. This may seem good (more than 6 seconds&#39; attention) but it also means that your resumé itself might play a lesser role in the deciding process (lessening the need for RDD). Instead, your Side Projects and GitHub Open Source contributions might play a larger role (though you can also highlight that on your resumé). --&gt;

&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 12 May 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t16-resume-driven-development.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t16-resume-driven-development.html</guid>
        
        
      </item>
    
      <item>
        <title>T15 Architect</title>
        <description>![CDATA[Can humans build a story-telling machine that can trick other human beings (a la the 'Turing Test')? Dartmouth College's Neukom Institute for Computational Science is hosting a competition ("DigiLit") to see if that can be done. I submitted a program (Architect) to this program. I think it has a good shot of winning (~40%).
]</description>
        <content>&lt;p&gt;Can humans build a story-telling machine that can trick other human beings (a la the &#39;Turing Test&#39;)? Dartmouth College&#39;s Neukom Institute for Computational Science is hosting a competition (&quot;DigiLit&quot;) to see if that can be done. I submitted a program (Architect) to this program. I think it has a good shot of winning (~40%).&lt;/p&gt;

&lt;p&gt;The idea behind &lt;a href=&quot;http://bregman.dartmouth.edu/turingtests/digilit&quot;&gt;DigiLit&lt;/a&gt; is simple. You build a machine that can accept an arbitrary noun prompt (&quot;wedding&quot;, &quot;sorrow&quot;, &quot;car keys&quot;, etc.). The machine then uses this noun prompt to generate a short story that is 7000 words or less. Then this short story is then presented to two panels (each with 3 judges). If you can convince a majority of one panel that your story is human-generated, then you win.&lt;/p&gt;

&lt;p&gt;This does seem like a difficult task. You must:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Have the computer accept arbitrary input&lt;/li&gt;
&lt;li&gt;Generate a story using the input&lt;/li&gt;
&lt;li&gt;Make sure the story is coherent enough to be readable&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Yet, I think I completed this task. After I finished writing my program (&lt;strong&gt;Architect&lt;/strong&gt;, named after the program in the Matrix trilogy), I decided to test it out. I chose a random noun prompt, and wrote a story based on it. I also had my program generate a story as well (using that same noun prompt). I then gave those two stories to 7 people. Story A was written by me, and Story B was written by the program.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;3 people correctly identified Story A as being written by a human.&lt;/li&gt;
&lt;li&gt;3 people wrongly identified Story B as being written by a human.&lt;/li&gt;
&lt;li&gt;1 person admitted he didn&#39;t know.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This means that 43% of the humans were fooled. That&#39;s pretty good. And it&#39;s good enough for me to submit it over to DigiLit.&lt;/p&gt;

&lt;p&gt;That doesn&#39;t mean that victory is assured, after all. 43% isn&#39;t exactly a majority. But consider that I really need to convince 2 out of 6 judges to have a good chance of &#39;convincing&#39; a whole panel of 3 judges (assuming that both judges sit on the same panel). That means I only need to convince 33% of all judges.&lt;/p&gt;

&lt;p&gt;To be 100% certain of convincing a panel though, I would need to convince 3 out of 6 judges (so that no matter how the judges are distributed, at least a majority of those I convinced would sit on a single panel). That does require me to be able to convince 50% of all judges. That doesn&#39;t seem too likely.&lt;/p&gt;

&lt;p&gt;One main problem with my study is that the format of my test and the DigiLit test is slightly different. In my test, each person is reading both stories individually and then making a choice. In DigiLit, the judges sit on a panel, have access to multiple stories (some human-generated and some machine-generated) so they can detect patterns and &#39;tells&#39;, and can talk to one another and share their insights. The mob will likely find more faults in a story than a single human can. So my study may likely overestimate how good my program actually is.&lt;/p&gt;

&lt;p&gt;But enough boring stats. Here&#39;s &lt;a href=&quot;https://github.com/tra38/Architect&quot;&gt;the source code&lt;/a&gt; of Architect and a brief description of how it works:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
  Have the computer accept input:
  &lt;ul&gt;
  &lt;li&gt;Plug the input into a madlib template: {INPUT} {LOCATION_TYPE}. For example:
    &lt;ul&gt;
      &lt;li&gt;Sorrow Academy.&lt;/li&gt;
      &lt;li&gt;Wedding Plaza.&lt;/li&gt;
      &lt;li&gt;Car Keys Muesum&lt;/li&gt;
    &lt;/ul&gt;
  The story will therefore be about a generated LOCATION, and not directly about the noun prompt. Here, I&#39;m assuming that reader will assume that when the program is writing about &quot;Sorrow Academy&quot;, they assume it to be symbolic of the actual noun in question (&#39;sorrow&#39;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;br&gt;
&lt;li&gt;Generate a story using that input:
  &lt;br&gt;
  &lt;ul&gt;
    &lt;li&gt;Randomly pick an introductory sentence from a corpus of introductory sentences.&lt;/li&gt;
    &lt;li&gt;Load the program with several pre-written passages.&lt;/li&gt;
    &lt;li&gt;Randomly pick a few of those passages. Insert in the LOCATION into the passages (so that the passages would therefore be about the input in question).&lt;/li&gt;
    &lt;li&gt;Between each passage, insert a &quot;transition passage&quot; to link the two passages together (providing an illusion of continuity between the passages). The &quot;transition passage&quot; was also pre-written.&lt;/li&gt;
    &lt;li&gt;Randomly pick an conclusion sentence from a corpus of conclusion sentences.&lt;/li&gt;
  &lt;/ul&gt;
This isn&#39;t a story with any planned plot or coherence. The program has no idea what it&#39;s writing. But since there is an illusion of continuity between passages, humans are able to read a &#39;narrative&#39;.
&lt;/li&gt;
&lt;br&gt;
&lt;li&gt;
  Have the story be thematically coherent enough to be readable.
  &lt;br&gt;
  &lt;ul&gt;
    &lt;li&gt;Each sentence of the story must have certain repeated symbols, themes, and characters within them, so that readers are more likely to assume that there is some purpose behind the words. (This approach was originally used in the &lt;a href=&quot;https://web.archive.org/web/20061112014356/http://www.brown.edu/Courses/FR0133/Fairytale_Generator/gen.html&quot;&gt;Fairy Tale Generator&lt;/a&gt; to create interesting stories based on random paragraphs.)&lt;/li&gt;
    &lt;li&gt;Since I&#39;m too lazy to hand-craft most of these sentences myself, I decided to use a preexisting generator (Abulafia&#39;s &lt;a href=&quot;http://www.random-generator.com/index.php?title=Film_Noir_Monologue&quot;&gt;Film Noir Monologue&lt;/a&gt; generator) to generate most of the paragraphs, introductory sentences, and conclusion sentences. Since this generator already had a prebuilt theme in mind (a cynical detective trying to solve a mysterious case), the resulting output does have some sort of thematic coherence. I then edited most of the paragraphs and sentences to provide even more thematic coherence.&lt;/li&gt;
    &lt;li&gt;The &#39;transition passages&#39;, however, were handwritten by me. Again, their goal is to provide thematic coherence and to &quot;fit&quot; with the rest of the passages.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This was the computer-generated story that I presented to my readers during the test:&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;It was a dark day—maybe normal for this time of year, but today the big city felt even darker and more sinister.&lt;/p&gt;

&lt;p&gt;Miss Kitty Rider prowled through my door like a tigress slinks into a Burmese orphanage—a pinup blonde with legs as far as you could want ’em. No dame her age could afford a coat like that, my money was right where my mind was: the gutter. She was to bad news what apple pie is to America. The dame was all business—before I could even close the office door, she told me she wants Investigator Blake dead. Turns out Blake is masterminding the gang violence, and wants to seize the Envy Foundation for himself by killing off all his rivals. I laughed at her; Blake may be a devil, but he&#39;s a devil I can work with. I wasn&#39;t going to sell him out.&lt;/p&gt;

&lt;p&gt;I asked Miss Kitty Rider if there was another way to end the gang violence, without having to take out Investigator Blake. Miss Kitty Rider responded me that if I wanted to bring an end to the violence, then I needed someone who is outside of the system. She recommended a fresh recruit from the police academy who was &#39;on the ball&#39;. Mr. Simpson. I foolishly took her advice.&lt;/p&gt;

&lt;p&gt;“An inside job…?” Simpson gasped timidly. “Well … No… not an inside job,” I growled. I could barely contain myself with this new guy. “Here’s the deal,” I muttered, “Why don’t I handle this case, while you make like a magnet … and flux off?”&lt;/p&gt;

&lt;p&gt;Before I left, Mr. Simpson offered me the phone number to the office. He claimed that the office had helped him greatly and that it can help me too. Desperate for any clues, I took Mr. Simpson&#39;s advice. I spoke to the receptionist for an hour, and jotted down everything she said.&lt;/p&gt;

&lt;p&gt;I had little to go on this time … but the office did manage to dig something up. G-Men, fighting crime and resisting corruption, deciding that the best way to fight crime and resist corruption is to kill everyone who might be a criminal and might be corrupt. Their current goal is to &#39;purify&#39; the Envy Foundation before moving onto other tourist attractions. I always knew that G-Men were a little &#39;special&#39;.&lt;/p&gt;

&lt;p&gt;I shoulda got out when I had the chance.&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Now, this story does have its faults. According to one of my readers, there isn&#39;t really any coherent plot, and no actual attempt to explain what&#39;s going on. And I agree with that reader. The stories that my program spits out are really more like &#39;prose poetry&#39;: the plot is really just an excuse to show off different evocative scenes. But I know that some people may like reading these stories anyway. Evocative scenes are enjoyable in their own right.&lt;/p&gt;

&lt;p&gt;In addition, another reader praised the computer-generated story as having &quot;linear progression&quot;, and a &quot;[natural] level of detail and organization and flow&quot;. This suggest that the existence of some underlining structure may also help to make this story more appealing to read.&lt;/p&gt;

&lt;p&gt;What is undeniable is that my computer has written a story.&lt;/p&gt;

&lt;p&gt;My entry is based on a simple trick: Humans has a tendency to see patterns in everyday life, even when no patterns exist. The very act of me placing words right next to each other imply that the words must have some &lt;em&gt;relationship&lt;/em&gt; with each other. So the humans create this &lt;em&gt;relationship&lt;/em&gt; within their own mind. This tendency for humans to see patterns where none exist has a name: &quot;apophenia&quot;.&lt;/p&gt;

&lt;p&gt;All I have to do is to provide some context and themes to help trick the humans into assuming that there must be meaning in the words that the program generates. Once that happens, the humans will then fill in the details by interpreting the program&#39;s words. The computer can write total nonsense...and that&#39;s okay, because the humans will just happily figure out the meaning of that nonsense. While the humans figure out that meaning, they thereby construct the story out of that nonsense. A story, therefore, appears from a mere collection of words.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Appendix A: Is This Story Of High-Quality?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I don&#39;t know. It appears that if the judges think that a story is human-written, they will generally assume it to be better...&lt;/p&gt;

&lt;p&gt;This sounds silly, but according to my data, the rating of the quality of the story is dependent on whether the judge assume the story is written by a human.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Out of the 3 people who correctly identified Story A as being written by a human, 2 of them gave that story higher marks than Story B, while 1 person gave Story B higher marks.&lt;/li&gt;
&lt;li&gt;Out of the 3 people who wrongly identified Story B as being written by a human, all of them gave Story B higher marks.&lt;/li&gt;
&lt;li&gt;The one person who didn&#39;t know which story was human-written? He gave both stories &lt;em&gt;equal&lt;/em&gt; marks.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is a pretty odd result and suggests to me that the &#39;origin&#39; of a story impacts how judges view its quality. This makes some sense: humans like reading what other humans have written, and if they assume that something is human-written, they are willing to think of it as good (even if it&#39;s not). But at the same time, I do have a small sample size, and it&#39;s possible that a different group of judges would determine the quality of a story more &quot;objectively&quot;.&lt;/p&gt;

&lt;p&gt;By the way, there have been several peer-reviewed studies about how humans&#39; perceptions of news articles can change based on whether they were told the news article was written by a &#39;human&#39; or by a &#39;robot&#39;, and I do plan on blogging on these articles later. I trust the results of those peer-reviewed studies over that of my unscientific study.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Appendix B: Can This Program &#39;Scale&#39;?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Using a single noun prompt, my story can generate 120 different short stories. Most people are not going to read all 120 stories. Instead, they&#39;ll only read a few computer-generated stories before moving onto the next content to consume. So I&#39;m fine with how the algorithm works currently. There&#39;s no reason to spend time writing more code than is necessary.&lt;/p&gt;

&lt;p&gt;That being said, the algorithm could &quot;scale&quot; upwards. If the program is given more passages, you could easily generate more short stories (or even &lt;em&gt;longer&lt;/em&gt; stories, possibly even novels). Finding those passages (and making sure they are all thematic coherent) may be somewhat difficult to do, and would most likely require using passages from Creative Commons or public domain works.&lt;/p&gt;

&lt;p&gt;Note that the &quot;transition phrases&quot; will have to be made more &#39;generic&#39; and reusable for different passages. Currently, I had to handwrite each transition phrase to handle specific situations (for example, I handwrote a the transition phrase to justify our unnamed detective leaving Mr. Simpson&#39;s place and calling the Office). Handwriting each transition phrase is a very laborious and tedious process. Having &quot;generic&quot; transition phrases, on the other hand, would have enabled me to focus on copying and pasting as many evocative scenes as possible into the generator.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 21 Apr 2016 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t15-architect.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t15-architect.html</guid>
        
        
      </item>
    
      <item>
        <title>Ai3</title>
        <description>![CDATA[I was 'inspired' to write this article because I read the botifesto "How To Think About Bots". As I thought the 'botifesto' was too pro-bot, I wanted to write an article that takes the anti-bot approach. However, halfway through writing this blog post, I realized that the botifesto...wasn't written by a bot. In fact, most pro-bot articles have been hand-written by human beings. This is not at all a demonstration of the power of AI; after all, humans have written optimistic proclamations about the future since the dawn of time.
]</description>
        <content>&lt;p&gt;I was &#39;inspired&#39; to write this article because I read the botifesto &lt;a href=&quot;http://motherboard.vice.com/read/how-to-think-about-bots&quot;&gt;&quot;How To Think About Bots&quot;&lt;/a&gt;. As I thought the &#39;botifesto&#39; was too pro-bot, I wanted to write an article that takes the anti-bot approach. However, halfway through writing this blog post, I realized that the botifesto...wasn&#39;t written by a bot. In fact, most pro-bot articles have been hand-written by human beings. This is not at all a demonstration of the power of AI; after all, humans have written optimistic proclamations about the future since the dawn of time.&lt;/p&gt;

&lt;p&gt;If I am to demonstrate that AI is a threat, I have to also demonstrate that AI &lt;em&gt;can be&lt;/em&gt; a threat, and to do that, I have to show what machines are currently capable of doing (in the hopes of provoking a hostile reaction).&lt;/p&gt;

&lt;p&gt;So this blog post has been generated by a robot. I have provided all the content, but an algorithm (&quot;Prolefeed&quot;) is responsible for arranging the content in a manner that will please the reader. Here is the &lt;a href=&quot;https://gist.github.com/tra38/8a6bf3743cd89687151c&quot;&gt;source code&lt;/a&gt;. And as you browse through it, think of what else can be automated away with a little human creativity. And think whether said automation would be a good thing.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Unemployment&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In 2013, Oxford Professors Frey and Obsurne argued that robots will replace 70 million jobs in the next 20 years (or 47% of all jobs in the USA). J.P Gownder, an analyst at the Boston-based tech research firm &quot;Forrester&quot;, makes a more optimistic case for technology in 2015, by claiming that by the year 2025, robots will only cause a net job loss of 9.1 million. (Both studies came from &lt;a href=&quot;http://www.wired.com/2015/08/robots-will-steal-jobs-theyll-give-us-new-ones/&quot;&gt;Wired&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;J.P. Gownder argued his lower estimate for job loss is because technology will create new jobs. In a Forbes article, J.P. Gowdner &lt;a href=&quot;http://www.forbes.com/sites/forrester/2015/08/24/robots-wont-steal-all-the-jobs-but-theyll-transform-the-way-we-work/#1d0356cd29a3&quot;&gt;justified his viewpoint&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We forecast that 16% of jobs will disspear[sic] due to automation technologies between now and 2025, but that jobs equivalent to 9% of today’s jobs will be created. Physical robots require repair and maintenance professionals — one of several job categories that will grow up around a more automated world. That’s a net loss of 7%: far fewer than most forecasts, though still a significant job loss number.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;The same &#39;adjustment&#39; for job gains was also done in a 2016 report by &lt;a href=&quot;http://reports.weforum.org/future-of-jobs-2016/employment-trends/&quot;&gt;World Economic Forum at Davos&lt;/a&gt;. &quot;[D]isruptive labour market changes&quot; (which includes not only AI, but other emerging tech such as 3D printing) could destroy 7.1 million jobs by 2020, while also creating 2 million jobs in smaller industry sectors. This means a net total of 5.1 million jobs lost.&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;&lt;td&gt;Study&lt;/td&gt;&lt;td&gt;Net Job Loss/Year&lt;/td&gt;
    &lt;tr&gt;&lt;td&gt;Frey and Obsurne (2013)&lt;/td&gt;&lt;td&gt;3.50 million&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;J.P. Gownder (2015)&lt;/td&gt;&lt;td&gt;0.91 million&lt;td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;World Economic Forum (2016)&lt;/td&gt;&lt;td&gt;1.02 million&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;


&lt;p&gt;There are some people who claim that we should not worry about robots because we&#39;ll just create brand new jobs out of thin air. To me, they are behaving like a complusive gambler boasting about how he can earn $2.82 by simply gambling away $10.&lt;/p&gt;

&lt;p&gt;In the long-term, perhaps, technology may finally erase the deficit in jobs and be seen as a net job producer. But that is exactly why we need to worry about this &quot;transition period&quot; to this &#39;long-term&#39;, whenever that may arrive.&lt;/p&gt;

&lt;p&gt;How will this new joblessness come into being? Personally, I do not foresee a bunch of people getting laid off immediately. Instead, companies will gradually reduce their hiring. Why hire a new [PROFESSION_NAME_HERE] when you can just get a robot to do the job for you? Existing employees may be deemed &#39;obsolete&#39;, but will be retrained with new skills that cannot be automated (yet).&lt;/p&gt;

&lt;p&gt;However, an academic paper entitled &lt;a href=&quot;http://miguelmorin.com/docs/Miguel_Morin_Great_Depression.pdf&quot;&gt;&quot;The Labor Market Consequences of Electricity Adoption: Concrete Evidence From The Great Depression&quot;&lt;/a&gt;, by Miguel Morin, does suggest that technological unemployment will indeed take the form of layoffs. During the Great Depression, the cost of electricity decreased for concrete plants. This increased the productivity of workers. Instead of increasing the production of concrete though, the concrete plants simply fired workers instead, thereby cutting their costs. &lt;a href=&quot;http://www.theatlantic.com/magazine/archive/2015/07/world-without-work/395294/&quot;&gt;The Atlantic&lt;/a&gt; also wrote several examples where technological unemployment occurred during times of recessions...when companies need to save money, humans get laid off and the cheaper bots come in instead.&lt;/p&gt;

&lt;p&gt;I hope I do not need to write out why unemployment is not good.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;float: left;&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Gartner_Hype_Cycle.svg/559px-Gartner_Hype_Cycle.svg.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The &quot;AI Winter&quot;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Artificial Intelligence is, ultimately, just a technology. And technologies can often times go through a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hype_cycle&quot;&gt;&#39;Hype Cycle&#39;&lt;/a&gt;, as coined by the research firm Gartner.&lt;/p&gt;

&lt;p&gt;At first, people become very interested in a brand new technology (a &quot;Technology Trigger&quot;). Companies start to over-invest in researching this technology, leading to a &quot;Peak of Inflated Expectations&quot; (i.e, a bubble). But the technology turns out to have major limitations. As a result, investment in the technology dries up (&quot;Trough of Disillusionment&quot;). Most companies either begin laying people off or closing down outright.&lt;/p&gt;

&lt;p&gt;Eventually, the survivors soon realize how to use the technology properly (&quot;Slope of Enlightenment&quot;), and we can finally use the technology in our day-to-day life (&quot;Plateau of Productivity&quot;). But as this picture from Wikipedia shows, the visibility of the technology in the Plateau of Productivity is much less than the visibility of that same technology in the Peak of Inflated Expectations. The brand new technology has done great things for us. It&#39;s just not as great as we hoped it to be. And does it justify the extreme waste seen in the &quot;Peak of Inflated Expectations&quot;?&lt;/p&gt;

&lt;p&gt;If this is some hypothetical graph, then it&#39;s not much to be worried about. But I have already lived through two tech bubbles: &lt;a href=&quot;https://en.wikipedia.org/wiki/Dot-com_bubble&quot;&gt;the dot-com bubble of 1997-2000&lt;/a&gt; and the &lt;a href=&quot;http://www.pbs.org/newshour/making-sense/unicorns-and-delusions-in-silicon-valleys-tech-bubble/&quot;&gt;current unicorn bubble&lt;/a&gt; (ending this year, at 2016). A cycle of &quot;irrational exuberance&quot; (&quot;Uber for [Plural Nouns]&quot;) followed by layoffs can be never a good thing. Especially if you have to live with the consequences. Any actual benefit caused by this overinvestment is only incidental.
&lt;br&gt;
&lt;br&gt;
I&#39;m afraid that this hype cycle can only get worse. The major reason the &lt;a href=&quot;https://en.wikipedia.org/wiki/United_States_housing_bubble&quot;&gt;American Real Estate Bubble of 2005-2007&lt;/a&gt; and the current unicorn bubble has grown as big as it did was due to a policy of &#39;low interest rates&#39; pursued by central banks. Investors are &#39;encouraged&#39; not to save money but instead to invest in risky ventures. The current interest in AI  suggest that investors may view this new technology as yet another chance to make money. These investors will probably pour way too much money into AI research (if they haven&#39;t started doing so already). And almost all of it will be exposed as wasteful in the &quot;Trough of Disillusionment&quot; stage.&lt;/p&gt;

&lt;p&gt;So why do I call the &quot;Trough of Disillusionment&quot; an &quot;AI Winter&quot;? Because I didn&#39;t come up with this name. It was invented in &lt;em&gt;1984&lt;/em&gt;. According to &lt;a href=&quot;https://en.wikipedia.org/wiki/AI_winter&quot;&gt;Wikipedia&lt;/a&gt;, the AI field had went through &lt;em&gt;two&lt;/em&gt; major AI winters (1974-1980, 1987-1993) and several &quot;smaller episodes&quot; as well.  Obviously our technology has improved. But human nature has not changed. If an AI bubble inflates, run.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Technological Dependence&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Some people believe that AI could serve as a tool that can perform routine, autonomous tasks. This frees up human to handle more creative tasks. Darrel West, the director for technology innovation at the Brookings Institution, embodies this sentiment of techno-optimism by saying:&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;&quot;It&#39;s good that we&#39;re figuring out how to use robots to make our lives easier. There are tasks they can do very well and that free humans for more creative enterprises.&quot;&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;For example, &lt;a href=&quot;http://articles.philly.com/2015-11-29/news/68626755_1_new-technology-textbook-robots&quot;&gt;robots are very good at writing 9-page textbooks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, I understand that some textbooks can be dry and boring. But it is hard to say that they are not &quot;creative enterprises&quot;. Yet, if you click on my above link, you will actually see Darrel West&#39;s quote, down to his very last words: &quot;more creative enterprises&quot;. Some human journalist told Darrel that a university is building a program that can write textbooks, and Darrel&#39;s only response boils down to: &quot;Oh, that&#39;s cool. More time for creativity then.&quot; (He also points to Associated Press&#39; own use of bots to write stories about sports to justify his viewpoint as well.)&lt;/p&gt;

&lt;p&gt;Does Darrel consider the act of writing &lt;em&gt;not creative&lt;/em&gt; then?&lt;/p&gt;

&lt;p&gt;Here&#39;s a dystopian idea. The term &quot;creative enterprise&quot; is a euphemism to refer to &quot;any activity that cannot be routinely automated away yet&quot;. Any task that we declare &#39;a creative expression of the human experience&#39; will be seen as &#39;dull busywork&#39; as soon as we invent a bot.  We delude themselves into thinking we are still the superior race, while slowly replacing all our usual activities with a bunch of silicon-based tools.&lt;/p&gt;

&lt;p&gt;This might be tolerable if your tools work 100% of the time. But &lt;a href=&quot;http://www.joelonsoftware.com/articles/LeakyAbstractions.html&quot;&gt;abstractions are leaky&lt;/a&gt;. If you rely on your tools too much, you open yourself up to terrible consequences if you ever lose access to the tools or your tools wind up malfunctioning. And the worst part is that your tools may fail at the very moment your (human) skills has decayed. After all, you didn&#39;t need to learn &quot;busywork&quot;. You focused all your efforts on mastering &quot;more creative enterprises&quot;.&lt;/p&gt;

&lt;p&gt;This skill decay has already happened to pilots. Thanks to the glory of automation on airplanes, &lt;a href=&quot;https://www.washingtonpost.com/local/trafficandcommuting/does-using-an-autopilot-dull-the-skills-of-us-commercial-pilots/2016/01/13/00e458fe-ba13-11e5-829c-26ffb874a18d_story.html&quot;&gt;the US Department of Transporation believe that many pilots are unable to fly airplanes in times of crises&lt;/a&gt;. When autopilot works, then all is well. When autopilot fails, then there&#39;s a real chance that the less capable human pilots make mistakes that winds up crashing the airplane.&lt;/p&gt;

&lt;p&gt;Far from AI freeing us to pursue worthier endeavours, it can only make us more dependent on technology and more vulnerable to disasters when that technology breaks. The only good news is that we can reduce our dependency. For example, the US Department of Transportation recommends that pilots should periodically fly their airplanes manually to keep their own skills fresh.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Angst&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It is not enough to build robots to handle the tedious tasks of interviewing human beings and hiring them to do routine tasks, but instead, &lt;a href=&quot;http://www.govexec.com/excellence/promising-practices/2015/11/algorithms-make-better-hiring-decisions-humans/124035/&quot;&gt;&quot;Algorithms Make Better Hiring Decisions Than Humans&quot;&lt;/a&gt;. It is not enough to have a robot be able to cheerfully play board games and find creative strategies, but instead &lt;a href=&quot;http://www.theverge.com/2016/3/15/11213518/alphago-deepmind-go-match-5-result&quot;&gt;&quot;Google&#39;s AlphaGo AI beats Lee Se-dol again to win Go series, 4-1&quot;&lt;/a&gt;. It is not enough to give video game AI the ability to simulate emotional decision-making by keeping track of a bunch of variables and behaving differently based on those variables, but instead &lt;a href=&quot;http://time.com/3674972/mario-lives-artificial-intelligence/&quot;&gt;&quot;Researchers Make Super Mario Self-Aware&quot;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, some people may argue that these algorithms are not examples of &quot;intelligence&quot;. The obvious conclusion must be that hiring people, beating people at Go, and playing Super Mario must also not be tasks that require intelligence.&lt;/p&gt;

&lt;p&gt;One of the problems with dealing with AI is the inherent vagueness of terms used to distinguish &quot;us&quot; (the humans) from &quot;them&quot; (the robots), leading to long and tedious arguments over whether this specific algorithm is an example of &quot;true AI&quot; without ever actually providing a decent definition of what is &quot;true AI&quot;. What  hurts matters even more is the &lt;a href=&quot;https://en.wikipedia.org/wiki/AI_effect&quot;&gt;AI Effect&lt;/a&gt;, where &lt;a href=&quot;http://www.dansdata.com/gz107.htm&quot;&gt;the goal posts are constantly shifting in response to new advances in technology&lt;/a&gt;. If you design a test to determine what is &quot;true AI&quot;, and then a machine passes the test, a new test will just get created instead.&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;Apparently, you see, when they said &quot;a machine will never be able to spot-weld a car together&quot;, they meant to say &quot;a machine will never be &lt;em&gt;aware&lt;/em&gt; that it&#39;s welding a car together&quot;.&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Some of the goal post shifting is justified: if we build something, we know how it works, and if we know how it works, we can see that it is artificial. And yet, again, at some point, the goal post shifting starts being seen as utterly ridiculous. Please don&#39;t say the act of writing novels is not a sign of intelligence just because &lt;a href=&quot;https://github.com/dariusk/NaNoGenMo-2015&quot;&gt;NaNoGenMo&lt;/a&gt; exists. (In fact, it is very possible that as AI improves, that we may be forced to confront the possibility that &lt;a href=&quot;https://plus.google.com/100656786406473859284/posts/Yp83aFwFJEr&quot;&gt;intelligence itself may not exist&lt;/a&gt;, which seems like a far worse fate than merely accepting the existence of AI.)&lt;/p&gt;

&lt;p&gt;One way around this problem is to essentially refuse to mention the term AI at all, and instead use a more neutral term, such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;&gt;machine learning&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Expert_system&quot;&gt;expert systems&lt;/a&gt;. &quot;Yeah that robot may not meet my arbitrary definition of intelligence, but it &lt;em&gt;is&lt;/em&gt; an expert in one specific domain area, and so I&#39;ll defer to its expertise.&quot; Yet the term of AI still continues to capture our imagination.&lt;/p&gt;

&lt;p&gt;Why?&lt;/p&gt;

&lt;p&gt;I think that our own ego is deeply invested in the idea that we are &#39;special&#39;, and that we are concerned when that &#39;specialness&#39; gets challenged. Michael Kearns, an AI researcher at the University of Pennsylvania, claimed that &quot;[p]eople subconsciously are trying to preserve for themselves some special role in the universe&quot;, &lt;a href=&quot;http://articles.philly.com/2004-01-15/news/25367871_1_new-robot-genes-yeast-cells&quot;&gt;in an article about an AI being built to conduct scientific experiments&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now Kearns doesn&#39;t care about protecting the human ego. But I do. I don&#39;t know what would happen to humanity when its self-image crumbles in the face of advanced machine capabilities. But I don&#39;t think it&#39;s something to look forward to.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Botcrime&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Consider the following quotes from the botifesto &lt;a href=&quot;http://motherboard.vice.com/read/how-to-think-about-bots&quot;&gt;&quot;How To Think About Bots&quot;&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;The work and the legal response raise crucial questions. Who is responsible for the output and actions of bots, both ethically and legally? How does semi-autonomy create ethical constraints that limit the maker of a bot?&lt;/p&gt;

&lt;p&gt;If you make a bot, are you prepared to deal with the fallout when your tool does something that you yourself would not choose to do? How do you stem the spread of misinformation published by a bot? Automation and “big” data certainly afford innovative reporting techniques, but they also highlight a need for revamped journalistic ethics.&lt;/p&gt;

&lt;p&gt;Bots might be effective tools for guiding people toward healthier lifestyles or for spreading information about natural disasters. How can policies allow for civically “good” bots while stopping those that are repressive or manipulative?&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;And so on and so forth. There are obviously legitimate fears about bots doing evil, either due to its interactions with the outside world or because it has been programmed to do evil by another entity.&lt;/p&gt;

&lt;p&gt;Raising questions about bot regulation is troubling though because they imply that these questions &lt;em&gt;must be answered&lt;/em&gt;. They do not have to be answered now, of course. But they do have to be answered fairly soon.&lt;/p&gt;

&lt;p&gt;Now only must they be answered, in the form of new government regulations, they must also be enforced. A law that is not enforced might as well not exist at all. Considering how successful we are currently in stopping preexisting spambots and social media manipulators, my hopes for effective enforcement of regulations is fairly low.&lt;/p&gt;

&lt;p&gt;What is worse is the fact that people will stand in the way of regulations. The authors (all creators of bots) strongly support regulation...except when said regulation might be used against them.&lt;/p&gt;

&lt;blockquote&gt;&lt;blockquote&gt;&lt;p&gt;Rumination on bots should also work to avoid policies or perspectives that simply blacklist all bots.  These automatons can and might be used for many positive efforts, from serving as a social scaffolding to pushing the bounds of art. We hope to provoke conversation about the design, implementation and regulation of bots in order to preserve these, and other as yet unimagined, possibilities.&lt;/p&gt;&lt;/blockquote&gt;&lt;/blockquote&gt;

&lt;p&gt;Again, a general blacklist of bots is a perfectly horrible idea (mostly because we cannot enforce it). But attempting to sort out &#39;good&#39; bots from &#39;bad&#39; bots seem like a rather dangerous and futile task. I can easily see the emergence of a &quot;pro-bot&quot; lobby that will stand against any but the most token of regulations, using doublespeak to claim that any use of technology has &quot;positive effects&quot;, while excusing away any problems the bots may cause.&lt;/p&gt;

&lt;p&gt;Alternatively, we can also see bot developers pitted against each other, decrying other people&#39;s uses of bots as being &quot;negative&quot; while championing their own use of bots as being &quot;positive&quot;. We need to have a legal system that can help evaluate whether bots are good or bad.&lt;/p&gt;

&lt;p&gt;According to Ryan Calo though, &lt;a href=&quot;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2737598&quot;&gt;the American legal system&#39;s views about robots are outdated and ill-suited to our brave new world&lt;/a&gt;. Judges generally see robots as &quot;programmable machine[s], by definition incapable of spontaneity&quot;, and ignore possible &#39;emergent properties&#39; that can exist when robots interact with society as a whole.&lt;/p&gt;

&lt;p&gt;Ryan Calo support the creation of &quot;a new technology commission, a kind of NASA-for-everything that can act as a repository of knowledge about robots to guide legal actors, including courts&quot;...but this commission seems very similar to that of an interest group, and one that may only have the interests of robot developers at heart, not that of society.&lt;/p&gt;

&lt;p&gt;It will take time to come up with the right balance between bot freedom and bot banning, if there really is any.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Conclusion&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In 2016, &lt;a href=&quot;http://www.evansdata.com/press/viewRelease.php?pressID=231&quot;&gt;Evans Data conducted a survey of 500 software engineers&lt;/a&gt; to find out what they feared the most. The largest plurality (29.1%) said that they feared AI taking their jobs. What&#39;s worse is that over 60% of software engineers thought that AI &quot;would be a disaster&quot;.&lt;/p&gt;

&lt;p&gt;This does not mean that these software engineers are Luddites. &quot;[O]ver three-quarters of the developers thought that robots and artificial intelligence would be a great benefit to mankind&quot;, claimed Janel Garvin (the CEO of Evans Data). &quot;Overlap between two groups was clear which shows the ambivalence that developers feel about the dawn of intelligent machines. There will be wonderful benefits, but there will also be some cataclysmic changes culturally and economically.&quot;&lt;/p&gt;

&lt;p&gt;There has been a lot of coverage about the rise of AI and its &#39;wonderful benefits&#39;. The goal of this post is to illustrate the &#39;cataclysmic changes&#39; and thereby make a implicit argument against AI.&lt;/p&gt;

&lt;p&gt;The dangers of AI are great, and we should not let the potentials of AI blind us to real risks. There are &lt;a href=&quot;tra38.github.io/blog/c11-ai2.html&quot;&gt;some solutions to help manage AI risk&lt;/a&gt; that I proposed in the past, but probably the most practical and sensible solution at the moment is to slow down AI development and think through these risks carefully. By slowing down progress, we can ensure that the changes won&#39;t be so &quot;cataclysmic&quot;, and that humanity can survive intact.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 11 Mar 2016 00:00:00 -0600</pubDate>
        <link>tra38.github.io/blog/ai3.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/ai3.html</guid>
        
        
      </item>
    
      <item>
        <title>C22 Sartre</title>
        <description>![CDATA[A few days ago, I read a blog post titled "Write code that was easy to delete, not easy to extend". At the top of this blog post was a quote...
]</description>
        <content>&lt;p&gt;A few days ago, I read a blog post titled &lt;a href=&quot;http://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to&quot;&gt;&quot;Write code that was easy to delete, not easy to extend&quot;&lt;/a&gt;. At the top of this blog post was a quote...&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“Every line of code is written without reason, maintained out of weakness, and deleted by chance.”&lt;/em&gt; Jean-Paul Sartre’s Programming in ANSI C[1]&lt;/p&gt;

&lt;p&gt;I was so fasinciated by this profound quote that I didn&#39;t even bother reading the rest of the blog post and decided to find this obscure book and read it myself.&lt;/p&gt;

&lt;p&gt;I don&#39;t agree with all of what Sartre has written; his ideas about individualism reads a bit too utopian for my tastes. However, his ideas are still interesting to read. Here are a few choice quotes from the book.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“Ah! How I hate the crimes of the new generation: they are dry and sterile as Assembly.”&lt;/li&gt;
&lt;li&gt;“A programmer is condemned to be free; because once thrown into the codebase, he is responsible for everything he does.”&lt;/li&gt;
&lt;li&gt;“Intellectuals cannot be good revolutionaries; they are just good enough to be programmers.”&lt;/li&gt;
&lt;li&gt;“If you want to deserve Hell, you need only stay in bed. The codebase is iniquity; if you accept it, you are an accomplice, if you change it you are an executioner.”&lt;/li&gt;
&lt;li&gt;“You must be afraid, my son. That is how one becomes an honest programmer.”&lt;/li&gt;
&lt;li&gt;“The more one is absorbed in fighting bad programming, the less one is tempted to write good programs.”&lt;/li&gt;
&lt;li&gt;“Do you think you can program innocently?”&lt;/li&gt;
&lt;li&gt;“As far as programmers go, it is not what they are that interests me, but what they can become.”&lt;/li&gt;
&lt;li&gt;“A programmer cannot will unless he has first understood that he must count on no one but himself; that he is alone, abandoned in the codebase in the midst of his infinite responsibilities, without help, with no other aim than the one he sets himself, with no other destiny than the one he forges for himself in his IDE.”&lt;/li&gt;
&lt;li&gt;“I do not give a damn about the previous programmers. They died for the codebase and the codebase can decide what it wants. I practice a live man’s politics, for the living.”&lt;/li&gt;
&lt;li&gt;“We programmers exist, that is all, and I find it nauseating.”&lt;/li&gt;
&lt;li&gt;“How can I, who was not able to retain my own past knowledge of the codebase, hope to teach another?”&lt;/li&gt;
&lt;li&gt;“I embraced Agile because its cause was just and I will leave Agile when it ceases to be just.”&lt;/li&gt;
&lt;li&gt;“Ah! Do not judge the gurus, young man, for they too have painful secrets.”&lt;/li&gt;
&lt;li&gt;“If a victory is told in detail, one can no longer distinguish it from a defeat.”&lt;/li&gt;
&lt;li&gt;“I respect orders but I respect myself too and I do not obey foolish design patterns made especially to humiliate me.”&lt;/li&gt;
&lt;li&gt;“What do you want to do with the language? Write Fizz-Buzz? What good is it to sharpen a knife every day if you never use it for slicing? Code is never more than a means. There is only one objective: power.”&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;[1]&quot;Jean-Paul Sartre’s Programming in ANSI C&quot; is a fictional book. The philosopher himself is real, as are the quotes, but almost all of them were modified to take into account the subject matter of programming.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Wed, 17 Feb 2016 00:00:00 -0600</pubDate>
        <link>tra38.github.io/blog/c22-sartre.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c22-sartre.html</guid>
        
        
      </item>
    
      <item>
        <title>T14 Abstract</title>
        <description>![CDATA[Yesterday, while reading an old computer science textbook "Programming and Problem Solving with C++", I saw a chapter on "Abstract Data Types" (ADTs) and was instantly curious. So I read the chapter, hoping to learn about this strange and mysterious things. I was surprised to find out that ADTs are not strange and mysterious at all. In fact, I have been writing them in my programming career.
]</description>
        <content>&lt;p&gt;Yesterday, while reading an old computer science textbook &quot;Programming and Problem Solving with C++&quot;, I saw a chapter on &quot;Abstract Data Types&quot; (ADTs) and was instantly curious. So I read the chapter, hoping to learn about this strange and mysterious things. I was surprised to find out that ADTs are not strange and mysterious at all. In fact, I have been writing them in my programming career.&lt;/p&gt;

&lt;p&gt;An ADT is any entity that contains data and specified behavior (methods/functions). For example, let us define a simple Bank Account ADT. This is a &quot;specification&quot; (a detailed list of what we want our ADT to do):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We should store how much money is in the account.&lt;/li&gt;
&lt;li&gt;We can withdraw money from this account.&lt;/li&gt;
&lt;li&gt;We can deposit money from this account.&lt;/li&gt;
&lt;li&gt;We know how much money is in the account.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;And here&#39;s an example of the Bank Account ADT, coded in Ruby...&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
  class BankAccount
    attr_reader :current_funds&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def initialize(amount)
  @current_funds = amount
end

def withdraw(amount)
  @current_funds -= amount
end

def deposit(amount)
  @current_funds += amount
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;That&#39;s it.&lt;/p&gt;

&lt;p&gt;Now, you may not like how I wrote this ADT. Perhaps you prefer not using classes and may wish to use a more &quot;functional&quot; approach to programming. Or maybe you just want to write this ADT in a different language.&lt;/p&gt;

&lt;p&gt;That&#39;s perfectly fine. Code the way that you wish. As long as you follow the specification listed above, the ADT is still valid. Your version of BankAccount is just as valid as mine. The implementation of an ADT is seperate from the specification of an ADT. That&#39;s why it is possible to refactor your code...so long as your code behaves the same way before and after the refactor.&lt;/p&gt;

&lt;p&gt;Now, the mind-blowing part is that you can build ADTs...&lt;strong&gt;using&lt;/strong&gt; ADTs. Suppose I want to create a Bank ADT that can store Bank Account ADTs, and I want to know how much money the Bank ADT has.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
  class Bank&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def initialize(array_of_bank_accounts)
  @accounts = array_of_bank_accounts
end

def total_funds
  sum = 0
  @accounts.each do |account|
    sum += account.current_funds
  end
  sum
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;  end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&quot;Programming and Problem Solving with C++&quot; recommends the use of ADTs because it makes programs simpler and easier to understand, thereby making code easier to write. The book uses an example of a car to illustrate its point:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;With abstraction, we focus on the &lt;em&gt;what&lt;/em&gt;, not the &lt;em&gt;how&lt;/em&gt;. For example, our understanding of automobiles is largely based on abstraction. Most of us know &lt;em&gt;what&lt;/em&gt; the engine does (it propels the car) but fewer of us know-or wnt to know-precisely &lt;em&gt;how&lt;/em&gt; the engine works internally. Abstraction allows us to discuss, think about, and use automobiles without having to know everything about how they work.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;And programming makes use of abstractions heavily, with some languages being entirely built on other languages. Ruby, for example, is built on C. Abstraction serves as a great way to manage complex code bases...and ADTs are the living paragons of abstraction.&lt;/p&gt;

&lt;p&gt;But &lt;a href=&quot;http://www.joelonsoftware.com/articles/LeakyAbstractions.html&quot;&gt;abstractions are &#39;leaky&#39;&lt;/a&gt;. What if there is some bug in my BankAccount ADT? That bug would harm my Bank ADT as well...and could even harm any ADTs that were built on top of my Bank ADT.&lt;/p&gt;

&lt;p&gt;So while ADTs are useful, you cannot be totally dependent on them. You have to be willing to look at the internal code of an ADT you&#39;re using and be able to debug it.&lt;/p&gt;

&lt;p&gt;It is not enough to know how to program using abstractions. You must also know how to program the abstractions &lt;em&gt;themselves&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 12 Feb 2016 00:00:00 -0600</pubDate>
        <link>tra38.github.io/blog/t14-abstract.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t14-abstract.html</guid>
        
        
      </item>
    
  </channel>
</rss>