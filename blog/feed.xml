<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tariq Ali&#39;s Blog</title>
    <description>A blog dedicated to showcasing my talents</description>
    <link>tra38.github.io/blog/</link>
    <atom:link href="tra38.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 07 Sep 2015 22:16:52 -0500</pubDate>
    <lastBuildDate>Mon, 07 Sep 2015 22:16:52 -0500</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>C19 Robojournalism</title>
        <description>![CDATA[Automated Insights and Narrative Science are two companies that specialize in producing software that can write news articles. But how do these news articles stack up to the human-written competition? A German researcher attempts to find out.
]</description>
        <content>&lt;p&gt;Automated Insights and Narrative Science are two companies that specialize in producing software that can write news articles. But how do these news articles stack up to the human-written competition? A German researcher attempts to find out.&lt;/p&gt;

&lt;p&gt;In the peer-reviewed article &lt;a href=&quot;http://kau.diva-portal.org/smash/get/diva2:699641/FULLTEXT01.pdf&quot;&gt;&quot;Enter the robot journalist: users’ perceptions of automated content&quot;&lt;/a&gt;, researchers randomly gave German undergraduate students one of two articles. One article was written by a human, and another was written by a program called &quot;Statsheet&quot; (which was created by Automated Insights). The German students were to read the article, rate it, and then say whether the article was written by a human being or a bot.&lt;/p&gt;

&lt;p&gt;The researchers asked two questions:&lt;/p&gt;

&lt;p&gt;1) Can the research students consistently identify whether an article is written by a human or a bot? - The answer is a resounding &quot;NO&quot;. While a majority of students correctly identified the bot-written article as being written by a bot, a majority of students also identified the &lt;strong&gt;human&lt;/strong&gt;-written article as being written by a bot. There is no statistically significant difference between how the students &#39;evaluated&#39; whether the article was written by a human or a bot.&lt;/p&gt;

&lt;p&gt;2) Are bots able to write prose of equal quality and crediblity as that of humans? - The answer is &quot;Yes, with one exception&quot;. There was no statistically significant difference between the quality of the journalism of the human and the bot...&lt;em&gt;except&lt;/em&gt; for the fact that the human&#39;s article was seen as more pleasant to read.&lt;/p&gt;

&lt;p&gt;(As a tangentical side note, the students rated the bot&#39;s article was being more informative, accurate, trustworthy, and objective...though the bot&#39;s article was also rated as more boring to read too. The students also rated the human&#39;s article as being well-written and coherent.&lt;/p&gt;

&lt;p&gt;The reason this note is tangentical is that these results are not &quot;statistically significant&quot;; if you were to run this same experiment with a different population, you would likely get different results.)&lt;/p&gt;

&lt;p&gt;Conclusion: The &quot;robojournalists&quot; are able to produce journalism that is able to equal that of the human competition. There are limits to the robojournalists though. They are unable to write prose that is &#39;pleasent to read&#39;. This may be a sign of limits to robojournalists&#39; creativity, which would give humans the edge. For now.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Mon, 07 Sep 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c19-robojournalism.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c19-robojournalism.html</guid>
        
        
      </item>
    
      <item>
        <title>C18 Narrative Science</title>
        <description>![CDATA["Practical Artifical Intelligence for Dummies: Narrative Science Edition" is a free e-book that provides a quick introduction into the AI field. It is also a treatise that outlined Narrative Science's approach towards dealing with AI.
]</description>
        <content>&lt;p&gt;&lt;a href=&quot;http://www.narrativescience.com/practical-ai&quot;&gt;&quot;Practical Artifical Intelligence for Dummies: Narrative Science Edition&quot;&lt;/a&gt; is a free e-book that provides a quick introduction into the AI field. It is also a treatise that outlined Narrative Science&#39;s approach towards dealing with AI.&lt;/p&gt;

&lt;p&gt;One of the taglines of this e-book is that it will &quot;demystify the hype, fear, and confusion about AI&quot;. Though the book primarly focused on explaining AI, it did pay some attention to the &#39;fears&#39; within popular culture, and attempted to address them in a &quot;roundabout&quot; way, without necessarily rebutting any specific fear.&lt;/p&gt;

&lt;p&gt;Narrative Science believed that AI only need to display intelligent behavior, and not necessarily need to think like human beings. As a result, Narrative Science concluded that technologies that humans take for granted are already AI. Voice recognition, recommendation engines, autocompletes, etc. are all commonly accepted within society, and yet all of these algorithms display intelligent behaviors.&lt;/p&gt;

&lt;p&gt;But these AI programs do not seek to take over the world or render people unemployed. Instead, these programs are just tools, there to help humans accomplish their day-to-day tasks. People are still in control and still receiving regular paychecks; all the AI did just made their lives easier. Narrative Science concluded that this trend would continue, and future AI programs will simply help humans instead of displacing them.&lt;/p&gt;

&lt;p&gt;If that was the crux of Narrative Science&#39;s argument, then I don&#39;t think this book&#39;s philosophy would have been interesting enough to blog about. But Narrative Science also surprisingly expressed some concern about AI proliferation. Narrative Science fears &lt;strong&gt;black boxes&lt;/strong&gt;: AI programs that are able to give answers but &lt;em&gt;fail&lt;/em&gt; to provide explainations for why it came up with those answers.&lt;/p&gt;

&lt;p&gt;Black boxes are not hypothetical concerns. Self-learning entities are being built and used already, such as &quot;evidence engines&quot; (IBM&#39;s Watson) and deep-learning networks (&#39;neural networks&#39;). These entities are able to learn about the world, but they cannot tell other people how they learn the world. You ask them a question, and all they give you an answer...with no context or reasoning behind the answer.&lt;/p&gt;

&lt;p&gt;Black boxes ruin trust. If you do not know how the AI came up with the answer, you cannot trust  whether the answer is actually correct[1]. Without trust, AI loses their potential as useful tools for humanity. A calcuator that gives the wrong answer every 30 minutes is not a very useful calcuator.&lt;/p&gt;

&lt;p&gt;Narrative Science claims that the best way to preserve trust in AI (and to keep their status as useful tools) is to enable the AI to communicate its internal thought process to human beings. That way, we can evaluate the AI&#39;s thought process and decide whether it is correct or incorrect. Narrative Science coincidentally happens to specialize in programming AI to write out newspaper articles and financial reports. So it may believe that its technology may be used to help AI programs write out why it made this or that decision.&lt;/p&gt;

&lt;p&gt;Narrative Science, however, has not yet figured out how to get these lack boxes to communicate. As black boxes are used in more and more critical industries, Narrative Science&#39;s apprehension about them will only grow. Already, Google has tried visualizing how its own black boxes works through its &lt;a href=&quot;googleresearch.blogspot.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;&quot;Google Dreams&quot;&lt;/a&gt;. More work will have to be done.&lt;/p&gt;

&lt;p&gt;[1]The alternative is to implicilty trust the AI&#39;s thought process...but when the AI inevitably make mistakes, you will not know how to prevent it from making future mistakes.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 22 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c18-narrative-science.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c18-narrative-science.html</guid>
        
        
      </item>
    
      <item>
        <title>C17 Postmorterm</title>
        <description>![CDATA[Devbootcamp does not have a conventional 'final exam' like most schools. Instead, to graduate from the program, you must work with a team of like-minded individuals to build a full-blown website within 7 days. This was my experience in trying to build &lt;a href=""Hashography", a website that would display tweets about a certain word onto a Google Map.
]</description>
        <content>&lt;p&gt;Devbootcamp does not have a conventional &#39;final exam&#39; like most schools. Instead, to graduate from the program, you must work with a team of like-minded individuals to build a full-blown website within 7 days. This was my experience in trying to build &amp;lt;a href=&quot;&quot;Hashography&quot;, a website that would display tweets about a certain word onto a Google Map.&lt;/p&gt;

&lt;p&gt;Our project lead, Evangeline Garreau, was inspired by a news article about a professor who was able to trace the usage of certain words on Twitter and develop a heat map displaying his results. Evangeline found the system cool and wanted to replicate that with a website that would display the history of word usage throughout the entire world.&lt;/p&gt;

&lt;p&gt;At first, the whole team was excited about the project. We wanted to determine the history of a word and be able to trace it from the very beginning. We also wanted to know where the words were being used, not just in the US, but globally. We had big dreams and aspirations for how to interpret the data and display it on a &quot;heat map&quot;. All we had to do is just to grab those Tweets from Twitter.&lt;/p&gt;

&lt;p&gt;But then those big ideas faced &quot;technical limitations&quot;, which would be a euphemism for &quot;cold hard reality&quot;. The best way to grab data from Twitter is to use an API. An API is a tool that enables websites (like Twitter) to communicate with other programs and websites (like &quot;Hashography&quot;). Twitter has two such APIs: a &quot;REST API&quot; that allows us to access past tweets, and a &quot;Streaming API&quot; that allows us to view present &#39;real-time&#39; tweets.&lt;/p&gt;

&lt;p&gt;It turns out that they were inherent limits to the Twitter REST API...such as the fact that Twitter would only allow us access to the last 7-10 days of Tweets. It also turns out that the professor that inspired Evangeline likely used the &quot;Streaming API&quot; for an entire year in order to grab the tweets necessary for him to discover the history. This option was incredibly impractical for our week-long project.&lt;/p&gt;

&lt;p&gt;Our passion for the project turned into panic. We tried searching for alternative ways of meeting our project. We looked at Google Trends, which gave us all the data we need to trace the history of the word usage...except that if we end up using it, we would be pretty much copy Google Trends. We tried switching to a multimiedia approach that would use Instagram&#39;s photographs to present a history of the word, except Instagram&#39;s own API gave us trouble too. At some point, some members of our team even half-jokingly supported violating Twitter&#39;s Terms of Service agreement by building robots that would &quot;scrape&quot; tweets.&lt;/p&gt;

&lt;p&gt;We floundered horribly.&lt;/p&gt;

&lt;p&gt;By Friday afternoon, it was agreed that we had to pivot away from the original idea behind the project. The group overall came to an agreement that it was more important to see where tweets are located rather than see the &quot;history&quot; of the word (after all, Google Trends already gave us a good history of the word). We decided to use the Twitter Streaming API to grab current tweets of a word and then display them onto a map. We also decided that we never really liked seeing &quot;heat maps&quot;, and switched to displaying data as points on a Google Map.&lt;/p&gt;

&lt;p&gt;At the time, it seemed that we had &quot;lost time&quot;, as we spent two days without any &quot;progress&quot;. But we have learned a lot more about our tools and our limitations, enabling us to catch up quickly. We also were more willing to try everything possible to resolve any disaster that would confront us, including preparing backup plans in case our current &quot;course-of-action&quot; was not working. We ended up producing a workable website by Sunday, and started polishing and improving on it.&lt;/p&gt;

&lt;p&gt;True, we still had problems after Sunday. We did not have enough automated tests and had to waste valuable time manually testing changes. We needed to learn the &quot;best practices&quot; for the new tools we were using. We needed to refactor our code constantly. We had trouble with designing our website to be user-friendly. But those were problems that we could &lt;strong&gt;fix&lt;/strong&gt; as part of standard maintenance, and they were much easier problems than trying to build the website in the first place. The very act of having a physical web presence gave the team a big morale boost.&lt;/p&gt;

&lt;p&gt;User feedback was excellent, and people saw our program as being &#39;beautiful and meaningful&#39;. Our &quot;pivot&quot; was a success.&lt;/p&gt;

&lt;p&gt;Why was it a success? For me, I think it was just due to the fact that we &lt;s&gt;panicked&lt;/s&gt; realized the extent of our situation early, and thus was more willing to do &quot;whatever it takes&quot; to accomplish our goals, including changing our goals to something more feasible. Our project lead, Evangeline Garreau, would instead likely credit the fact that we had good group dynamics and that we respected each other&#39;s ideas. (Of course, both thoughts may be true.) And, of course, we may have just been lucky.&lt;/p&gt;

&lt;p&gt;Overall, we did a good job with this website, and it showed us ultimately that we can still produce beautiful and meaningful work without necessarily staying true to the original idea. We were humbled by the experience, and only by being humble can we begin to learn from our surroundings. We had fun, and we learned a lot.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 13 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c17-postmorterm.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c17-postmorterm.html</guid>
        
        
      </item>
    
      <item>
        <title>C16 Lovelace Test 2</title>
        <description>![CDATA[In my previous blog post, I wrote about two tests used to determine whether AI is intelligent. However, it turns out that I did not fully understand one of those tests: the Lovelace Test.
]</description>
        <content>&lt;p&gt;In my previous blog post, I wrote about &lt;a href=&quot;http://tra38.github.io/blog/c15-lovelace-test.html&quot;&gt;two tests used to determine whether AI is intelligent&lt;/a&gt;. However, it turns out that I did not fully understand one of those tests: the Lovelace Test.&lt;/p&gt;

&lt;p&gt;The Lovelace Test was named after Ada Lovelace (the first computer programmer) who argued famously that computers will only follow instructions that programmers give it. According to my summary of this test, a program must match the following criteria:&lt;/p&gt;

&lt;p&gt;&quot;1. The program must be able to design something &#39;original&#39; and &#39;creative&#39; (such as a story, music, idea, or even another computer program).
2. The program itself is a result of processes that can be &#39;reproduced&#39;. (In other words, it does not rely on some bug in the &#39;hardware&#39; that the program is running on.)
3. The programmer must not know how the program actually works.&quot;&quot;&lt;/p&gt;

&lt;p&gt;I thought that this test is flawed because it excludes the possibility of bugs or programs being so overly complex that a programmer would not be able to understand them.&lt;/p&gt;

&lt;p&gt;But it turns out that my summary of this test was based on &lt;a href=&quot;http://motherboard.vice.com/read/forget-turing-the-lovelace-test-has-a-better-shot-at-spotting-ai&quot;&gt;a Vice article&lt;/a&gt;, which neglected one additional criteria: the program must not be a result of bugs. In the original paper &lt;a href=&quot;http://kryten.mm.rpi.edu/lovelace.pdf&quot;&gt;&quot;Creativity, the Turing Test, and the (Better) Lovelace Test&quot;&lt;/a&gt;, the authors specifically addressed the idea of bugs, and why their presence does not mean intelligence.&lt;/p&gt;

&lt;p&gt;“Sure, we all know that computers do things we don’t intend for them to do. But that’s because we’re not smart and careful enough, or — if we’re talking about rare hardware errors — because sometimes microscopic events unfold in unforeseen ways. The unpredictability in question does not result from the fact that the computer system has taken it upon itself to originate something. To see the point, consider the assembling of your Toyota Camry. Suppose that while assembling a bumper, a robot accidentally attaches a spare tire to the bumper instead of leaving it to be placed in its designated spot in the trunk. The cause of the error, assume, is either a ﬂuke low—level hardware error or a bug inadvertently introduced by some programmers. And suppose for the sake of argument that as serendipity would have it, the new position for the tire strikes some designers as the ﬁrst glorious step toward an automobile that is half conventional sedan and half sport utility vehicle. Would we want to credit the malfunctioning robot with having originated a new auto? Of course not.”&lt;/p&gt;

&lt;p&gt;Under this idea, the Lovelace Test does indeed have meaning. It may be impossible to actually pass (as originally designed), as I actually do support Ada Lovelace&#39;s contentions that computer programs only do stuff we tell it to do. But I do not think that the ability to tell programs what to do automatically renders programs non-intelligent. Even intelligent species like humans have to receive instructions and learn from other intelligent beings.&lt;/p&gt;

&lt;p&gt;But at least the test has rational and logical meaning, and places a higher barrier than the Turing Test. So this blog post is an apology of sorts for misrepresenting the Lovelace Test in my previous post. If you do agree with the premises of the test, then it would serve as a valid way of determining intelligence. That being said, this passage on bugs raises three questions about the Lovelace Test:&lt;/p&gt;

&lt;p&gt;1) Who do we credit then for making the new car, if not the robot? We can’t credit the designers...they did not come up with the idea or build the prototype. We can’t credit the programmers or the low-level hardware error: they made mistakes and were not doing their job. The only entity that actually built the new auto was the malfunctioning robot, and is not creation a type of origination?&lt;/p&gt;

&lt;p&gt;2) If machines do something new and unexpected, it is not a sign of machine intelligence, but human stupidity. This seems somewhat more disturbing to me, especially as we may soon easily build machines so complex that we cannot even begin to understand and comprehend how they work. How would the &quot;stupid&quot; humans be able to handle dealing with these mechanical brutes (especially in terms of debugging)?&lt;/p&gt;

&lt;p&gt;3) These &quot;complex&quot; machines may, of course, accomplish their assigned tasks efficiently than a human can. Does that make the machines&#39; non-intelligence &quot;better&quot; than human intelligence? Is &quot;intelligence&quot;, then, an overrated concept?&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Wed, 12 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c16-lovelace-test-2.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c16-lovelace-test-2.html</guid>
        
        
      </item>
    
      <item>
        <title>C15 Lovelace Test</title>
        <description>![CDATA[Today, we are making great strides in producing bots that can automate tasks efficently. This can be a major problem for us, as AI automation may endanger jobs. But are these bots that are replacing humans actually 'intelligent'? Two tests exist to determine whether an AI is intelligent. In my opinion, both tests are flawed.
]</description>
        <content>&lt;p&gt;Today, we are making great strides in producing bots that can automate tasks efficently. This can be a major problem for us, as &lt;a href=&quot;http://tra38.github.io/blog/c10-ai.html&quot;&gt;AI automation may endanger jobs&lt;/a&gt;. But are these bots that are replacing humans actually &#39;intelligent&#39;? Two tests exist to determine whether an AI is intelligent. In my opinion, both tests are flawed.&lt;/p&gt;

&lt;p&gt;The Turing Test has traditionally been used as a way to determine whether an AI is intelligent. If a machine is able to convince a human through conversation that the machine is human, then the machine can be said to have intelligence. The test sounded like a good idea at the time...but it turns out that it&#39;s too easy to pass. You just have to figure out how to string sentences together well-enough to fool humans. In 2011, an AI named &lt;a href=&quot;https://en.wikipedia.org/wiki/Cleverbot&quot;&gt;Cleverbot&lt;/a&gt; was able to convince 59.3% of humans at a festival that it was a human, while in 2014, &lt;a href=&quot;motherboard.vice.com/read/how-a-computer-beat-the-turing-test-by-pretending-to-be-a-13-year-old-boy&quot;&gt;&quot;Eugene Goodman&quot;&lt;/a&gt; pretended to be a 13-year-old Ukrainian and convinced over 30% of judges. In 2015, &lt;a href=&quot;motherboard.vice.com/read/the-poem-that-passed-the-turing-test&quot;&gt;a PhD student&lt;/a&gt; submitted several computer-generated poems to literary maganizes and succesfully got one of them published.&lt;/p&gt;

&lt;p&gt;Deceit is a poor subsitute for intelligence.&lt;/p&gt;

&lt;p&gt;Some computer scientists have designed an alternative to the Turing Test, called the &lt;a href=&quot;http://motherboard.vice.com/read/forget-turing-the-lovelace-test-has-a-better-shot-at-spotting-ai&quot;&gt;&quot;Lovelace Test&quot;&lt;/a&gt;, named after Ada Lovelace, the first computer programmer. Ada Lovelace argued that computers could never be intelligent, simply because computers will always do what programmers tell it to do.&lt;/p&gt;

&lt;p&gt;To pass the Lovelace Test:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The program must be able to design something &#39;original&#39; and &#39;creative&#39; (such as a story, music, idea, or even another computer program).&lt;/li&gt;
&lt;li&gt;The program itself is a result of processes that can be &#39;reproduced&#39;. (In other words, it does not rely on some bug in the &#39;hardware&#39; that the program is running on.)&lt;/li&gt;
&lt;li&gt;The programmer must not know how the program actually works.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This test also seemed like a good idea, except when it isn&#39;t. This test is very easy to pass, even easier than the Turing Test. If a programmer writes up a program that is overly complex, then the programmer would not know how the program works. Therefore, the program would pass the Lovelace Test easily. (Any output by this complex program would could then be defined as being &#39;original&#39; and &#39;creative&#39; by at least one other person.)&lt;/p&gt;

&lt;p&gt;What would be more interesting is thinking about would this hapless programmer do next. If the programmer then studied the code carefully, made educated guesses, and slowly refactored the code, then did the program loses the intelligence it previously gained from its complexity? If that is true, then we should look at scientists who are trying to understand the human mind. If we start getting a good sense about how our brain works, do we lose our own &#39;intelligence&#39; in the process?&lt;/p&gt;

&lt;p&gt;The main problem I have with both the Lovelace Test and the Turing Test is that it assumes that intelligence is a binary trait. Either you have it or you do not. But it seems intelligence would be better modeled as a continuum. AI, of course, are not as intelligent as human beings (at least, not yet). But AI still have some intelligence. We can even bring in the idea of &quot;multiple intelligences&quot;: humans are good at creativity while AI are good at solving math. Just because humans are &#39;top dogs&#39; does not mean that we can disrespect &#39;lesser dogs&#39;.&lt;/p&gt;

&lt;p&gt;Of course, I do not think that Duke Greene, my instructor at DevBootCamp, would even like the idea of measuring intelligence in the first place. He quoted a philosopher who (and I am paraphrasing here) that if bunnies thought like humans, then bunnies would consider themselves to be the most intelligent beings on Earth and the second-intelligent beings would be those beings who take orders from the bunnies. Prehaps intelligence itself merely a codeword for &quot;thinking like us&quot;, and we should instead respect AI as what it is, rather than hope for it to turn into something it is not.&lt;/p&gt;

&lt;h6&gt;#&lt;/h6&gt;

&lt;p&gt;As a side-note: I do like the idea of having code so complex humans would not understand how it actually works. Such a thing would make the code unpredictable, and unpredictable code is code that cannot be trusted to do work as reliably as a human can. (In fact, in a blog post about how to stop AI automation from destorying jobs, I mused about giving AI &lt;a href=&quot;http://tra38.github.io/blog/c11-ai2.html&quot;&gt;&#39;free will&#39;&lt;/a&gt; to make them less appealing as job candidates. Unpredictablity can also work to discourage people from hiring bots.)&lt;/p&gt;

&lt;p&gt;The problem is that unpredictable code is &lt;strong&gt;bad&lt;/strong&gt;. Such code will be dismissed as being buggy and unmaintainable, especially by the programmer who wrote the code in the first place. Programmers will invest time in trying to simplify the program&#39;s complexity and refactor it so that the code can end up being predictable and simple to understand. If a program passes the Lovelace Test, it is not a sign of an AI renaissance. It is a sign that something has gone horribly wrong.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sun, 02 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c15-lovelace-test.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c15-lovelace-test.html</guid>
        
        
      </item>
    
      <item>
        <title>C14 Surviving Dbc</title>
        <description>![CDATA[DevBootCamp has been a rough journey, but I know that it will give me the skill and confidence necessary for me to survive in the tech world.
]</description>
        <content>&lt;p&gt;DevBootCamp has been a rough journey, but I know that it will give me the skill and confidence necessary for me to survive in the tech world.&lt;/p&gt;

&lt;p&gt;Today, I passed a major assessment in DevBootCamp, thereby ensuring that I will move forward in the program. The feedback I got from my assessor was excellent, telling me my weaknesses (failing to use prototypes in Javascript, accidentally destroying the DOM element instead of simply hiding it, having complicated code when simple code would do). But now that I know these weaknesses, I can now move to correct them. Progress is being made.&lt;/p&gt;

&lt;p&gt;I would not be where I was today without asking for help. Indeed, I asked for help a lot during the assessment, perhaps more so than necessary. There has been instances where I asked for help only to be able to solve the problem by myself, with the guide just sitting there watching me explain the problem and figure out what&#39;s wrong. The lesson I learnt from today is that I need to be more self-confident of my own abilities. At the same time, I still need to know when to ask for help...but only when I know when I need that help.&lt;/p&gt;

&lt;p&gt;After the assessment, DevBootCamp gives us 1.5 days to work on any project we want, so long as we use an API (Application Programming Interface). I decided to work on Friend-Computer, a program that will automatically generate blog posts. I had thought that the program would take me 2 hours to complete, but instead it took me all day. However, I did manage to &lt;a href=&quot;http://friendcomputer.herokuapp.com/&quot;&gt;successfully create it&lt;/a&gt;, and most people are sastified with the results, though there is some critique about the &quot;grammar&quot; of the posts. The lesson I learnt here is that I need to prepare for the fact that I &lt;strong&gt;don&#39;t&lt;/strong&gt; know how long a project would take, and prepare myself accordingly. I must avoid overconfidence, lest I get burned.&lt;/p&gt;

&lt;p&gt;Indeed, when I entered into DevBootCamp, I had the intention of updating my blog every week. This, of course, did not happen, as I was more focused on preparing for the assessment than producing content. But if DevBootCamp helps me be a better programmer, nay, a better person, then the experience will all be worth it.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 23 Jul 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c14-surviving-dbc.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c14-surviving-dbc.html</guid>
        
        
      </item>
    
      <item>
        <title>T11 Documentation</title>
        <description>![CDATA[If you are given a powerful program, but are not given the instructions on how to use it, then the program is worthless to you. Documentation is essential to understanding code.
]</description>
        <content>&lt;p&gt;If you are given a powerful program, but are not given the instructions on how to use it, then the program is worthless to you. Documentation is essential to understanding code.&lt;/p&gt;

&lt;p&gt;Yet, documentation is neglected in the programming community. Many people tend to prioritize producing quality code over writing out how the code is supposed to work. While this may seem sensible in the short-term, in the long-term, it leads to code that is difficult for people to use. Many prospective programmers will be scared off by the complexitiy of the code, and the few that remain will spend valuable time understand what the program does instead of actually improving it.&lt;/p&gt;

&lt;p&gt;The most common form of documentation is &#39;human-readable paperwork&#39;. Examples of such paperwork includes READMEs, flowcharts, diagrams, technical manuals, and code comments. This sort of documentation is useful for people to understand the code quickly (provided the paperwork itself is well-written). However, the documentation can quickly become obsolete whenever a new update to the program is released. As a result, such documentation must be updated constantly for it to be useful. The constant strain of updating &quot;human-readable paperwork&quot; is a major reason why people tend to fear documentation altogether.&lt;/p&gt;

&lt;p&gt;But documentation is still necessary. So programmers have been exploring &lt;em&gt;alternatives&lt;/em&gt; to human-readable paperwork. These alternatives are tied directly to the source code, so whenever the code is updated, the documentation is too. These alternatives include tests, names, and self-documenting code.&lt;/p&gt;

&lt;p&gt;1) Automated tests can inform programmers about about how the code is supposed to behave. By running the tests, you can learn whether the program actually does end up behaving as it is supposed to. Since automated tests are more effective at debugging than manual testing, programmers are encouraged to have these tests anyway. So the &quot;documentation&quot; is seen as a &#39;bonus&#39;. Automated tests however only tell you what code is supposed to do, and not &lt;em&gt;why&lt;/em&gt;. You also have to still write the tests in question, and write enough tests to convey all that is essential to know about the program.&lt;/p&gt;

&lt;p&gt;2) Names convey information about a particular section of code. Whether you are naming a variable (list_of_dogs), a method (add_dog_to_list), or even a class (List), you are sending a message about what that code does (and usually more quickly than you would with a comment). Knowing what the code is supposed to do helps someone also understand how the code is supposed to work as well. However, it is extremely difficult to name variables properly and what seems like a clear variable name to the original programmer may not be to future programmers.&lt;/p&gt;

&lt;p&gt;3) Self-documenting code refers to having a consistent &quot;style guide&quot; within the code proper and ahdering to it. If a programmer is familiar with the &#39;coding conventions&#39; that the &quot;style guide&quot; promotes, then the programmer is better able to understand the program. There are innumerable style guides for every language though, so someone who is not familiar with the conventions of your guide may struggle with understanding the code. It may be difficult to convince all programmers on the team to follow the chosen &quot;style guide&quot; properly.&lt;/p&gt;

&lt;p&gt;Of course, ideally, a programmer would want all types of documentation: human-readable paperwork, automated tests, names and self-documenting code. The problem is that documentation takes time to produce, and skill to produce &lt;strong&gt;well&lt;/strong&gt;. It is essential to have good documentation, but there are many ways to do it, and some programmers will naturally graviate towards some forms of documentation while shying away from others.&lt;/p&gt;

&lt;!-- It is tempting to also have tests also play a secondary role of informing people about the code tends to be 

 &quot;self-documenting code&quot;: code that is easy for programmers to understand. The two parts of self-documenting code are variable names and automated testing.

Variable names can also serve as documentation. Variable names help to explain what is the purpose of the &#39;variable&#39; in the program. However, it is extremely difficult to name variables properly and 
 --&gt;

&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 04 Jul 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t11-documentation.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t11-documentation.html</guid>
        
        
      </item>
    
      <item>
        <title>C12 Fake Papers</title>
        <description>![CDATA[The most popular way of measuring the effectiveness of a scientist is by knowing how many other people 'cite' their work. If lots of people are referring to your research, then your research must therefore be good. This metric is codified as the H-Index.
]</description>
        <content>&lt;p&gt;The most popular way of measuring the effectiveness of a scientist is by knowing how many other people &#39;cite&#39; their work. If lots of people are referring to your research, then your research must therefore be good. This metric is codified as the &lt;a href=&quot;https://en.wikipedia.org/wiki/H-index&quot;&gt;H-Index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But every metric has its own flaws. In 2010, Cyril Labbé (a computer scientist) &lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-00713564/document&quot;&gt;was able to manipulate the H-Index by publishing 102 computer-generated research articles&lt;/a&gt;, many of whom cited each other. Since the papers all cited each other, the &quot;author&quot; of all these fake papers (Ike Antkare) had his H-index score boosted. The fake research papers also cited legitimate research papers to disguise the ruse.&lt;/p&gt;

&lt;p&gt;Ike Antkare soon became the 21st highest-cited scientist in the world, even outclassing Albert Einstein.&lt;/p&gt;

&lt;p&gt;The computer-generated research articles were created using &lt;a href=&quot;https://en.wikipedia.org/wiki/SCIgen&quot;&gt;SCIgen&lt;/a&gt;, a program designed to produce &quot;context-free&quot; research papers that &lt;em&gt;seems&lt;/em&gt; to be like real scientific papers, but are actually meaningless. If anybody bothered to read them, then the articles would be known to be false. The inventors of SCIgen intended to use this software to expose academic conferences and journals that accepts research papers without bothering to read them.&lt;/p&gt;

&lt;p&gt;Once Cyril Labbé exposed the ruse he made, people started reading the papers that Ike Antkare wrote. Ike Antkare lost his prestigious H-index score, as search engines began removing Ike&#39;s papers from their databases.&lt;/p&gt;

&lt;p&gt;This incident exposes a very important part about metrics...you cannot rely on only one. If you had just relied on the H-index to tell you how effective a scientist is at research, then Ike Antkare would have been a star. Only by reading Ike&#39;s papers will you be able to know the truth about Ike and avoid being fooled.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 26 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c12-fake-papers.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c12-fake-papers.html</guid>
        
        
      </item>
    
      <item>
        <title>E5 Writing</title>
        <description>![CDATA[Researchers want to help other people learn from them, so they write peer-reviewed papers, blog posts, etc. But researchers are also bad at writing, making it difficult for other people to learn from their research. So I was very interested in reading Steven Pinker’s article in The Chronicle of Higher Education entitled “Why Academics Stink At Writing”. Here's a summary of what Steven Pinker has written, so that you can learn why it is hard to write your own research to the general public.
]</description>
        <content>&lt;p&gt;Researchers want to help other people learn from them, so they write peer-reviewed papers, blog posts, etc. But researchers are also bad at writing, making it difficult for other people to learn from their research. So I was very interested in reading Steven Pinker’s article in The Chronicle of Higher Education entitled &lt;a href=&quot;http://chronicle.com/article/Why-Academics-Writing-Stinks/148989/&quot;&gt;“Why Academics Stink At Writing”&lt;/a&gt;. Here&#39;s a summary of what Steven Pinker has written, so that you can learn why it is hard to write your own research to the general public.&lt;/p&gt;

&lt;p&gt;There are three “general” reasons why it is difficult to understand what a researcher is saying, that Pinker acknowledges has already been discussed at length:
1) He doesn’t have anything to say, and he’s just making stuff up to hide his lack of knowledge.&lt;/p&gt;

&lt;p&gt;2) The topic is so complex that you have to use complicated language (or “jargon”) to explain it.&lt;/p&gt;

&lt;p&gt;3) Other resarchers expect him to use jargon, and if he refuses, they may reject his papers as not being serious enough.&lt;/p&gt;

&lt;p&gt;Pinker offer three other reasons:&lt;/p&gt;

&lt;p&gt;Pinker Reason #1) Researchers want to believe that the topic is complex and that only a few people can understand it. Therefore, they use “jargon” to prove their belief to themselves. The researcher does not want the reader to understand what he is saying because then it would mean the topic is easy and that the researchers has just wasted five to ten years of his life studying it.&lt;/p&gt;

&lt;p&gt;Pinker identifies these tactics used by researchers to convince themselves that the topic is difficult:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Providing detailed references to previous research that was used to create his own research work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Talking about what other researchers are currently talking about&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apologizing for his article being too controversial and difficult to understand&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Refusing to commit to any opinion on the topic, as the researcher fears that another researcher may prove his opinion wrong.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using scare-quotes to distance themselves from common idioms uttered by the general public (for example: “I think that this student is a real ‘quick-study’”).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Pinker Reason #2) The Curse of Knowledge. A researcher may be tempted to assume that the reader is as smart as him. This is a bad assumption to make, and can lead to writing that may be clear to someone as smart as the researcher, but impossible for a less-smart reader to understand. For example, the researcher may use abbreviations when the reader does not know their meaning, or casually use Latin words when a reader only knows English.&lt;/p&gt;

&lt;p&gt;Pinker Reason #3) “Chunking”. Scientists want to create container words to hold several related ideas together. This makes it easier for the researcher to organize his own thoughts, but more difficult for the reader to understand those thoughts. (For example: instead of “calling the police”, a researcher would write “law-enforcement perspective”, a container word to refer to many different ways of involving ‘law enforcement’, such as “calling the police”.)&lt;/p&gt;

&lt;p&gt;Pinker wants researchers to be able to write clearly. But writing clearly is very difficult to do. He advertises his own free downloadable booklet, “How Can You Fix Your Writing?” to help researcher out. Hopefully, I will get time to read his booklet and be able to convey his information accurately.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 18 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/e5-writing.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/e5-writing.html</guid>
        
        
      </item>
    
      <item>
        <title>T10 Writing Tests</title>
        <description>![CDATA[Testing is an important part of any programmer's life, to detect and eliminate bugs. But writing automated tests themselves can be rather costly endeavour. Not only does it take time to write your tests, but you also must make sure your tests are working properly as well. To reduce your costs, you need to reduce the amount of tests you write.
]</description>
        <content>&lt;p&gt;Testing is an important part of any programmer&#39;s life, to detect and eliminate bugs. But writing automated tests themselves can be rather costly endeavour. Not only does it take time to write your tests, but you also must make sure your tests are working properly as well. To reduce your costs, you need to reduce the amount of tests you write.&lt;/p&gt;

&lt;p&gt;According to the &lt;a href=&quot;poodr.com&quot;&gt;Practical Object-Oriented Guide to Ruby&lt;/a&gt;, automated tests should only test the &lt;em&gt;outputs&lt;/em&gt; of your code. Trying to test &lt;strong&gt;how&lt;/strong&gt; that code calcuates the output would lead to your tests breaking every time you change that code. This will waste a lot of time and energy that could be spent on other aspects of your programs. Just test the outputs of a program.&lt;/p&gt;

&lt;p&gt;POODR also suggests that you should check to see if this output ever actually gets used anywhere in the program or displayed to the user. If nobody (not even the code) gets to see this output, then it&#39;s possible that this output is unncessary. You can then delete the code that produces the output without fear, and will not have to worry about testing this code as well. You have saved yourself time and grief in maintaining the code that produces your output.&lt;/p&gt;

&lt;p&gt;Finally, POODR recommends not testing private methods. Private methods are methods that you want only the computer program to use. Since you do not want any human using them, you are free to not test these methods. It can be assumed that the program will end up using those private methods to calcuate the outputs, and if the private methods are bugged, then the resulting outputs would be wrong as well. Then the tests that you have written will indicate to you that a bug exists in your code, and you can then fix the private methods in question.&lt;/p&gt;

&lt;p&gt;I wrote a blog post recently on the differences between &lt;a href=&quot;/blog/t8-tech.html&quot;&gt;automated testing and manual testing&lt;/a&gt;. One of the points I made is how automatic tests are more efficent than manual testing but are also more expensive to create. By reducing the number of tests you create, you reduce your costs, and thereby benefit more from automated testing.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Wed, 10 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t10-writing-tests.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t10-writing-tests.html</guid>
        
        
      </item>
    
  </channel>
</rss>