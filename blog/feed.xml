<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tariq Ali&#39;s Blog</title>
    <description>A blog dedicated to showcasing my talents</description>
    <link>tra38.github.io/blog/</link>
    <atom:link href="tra38.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 17 Aug 2015 15:56:38 -0500</pubDate>
    <lastBuildDate>Mon, 17 Aug 2015 15:56:38 -0500</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>C17 Postmorterm</title>
        <description>![CDATA[Devbootcamp does not have a conventional 'final exam' like most schools. Instead, to graduate from the program, you must work with a team of like-minded individuals to build a full-blown website within 7 days. This was my experience in trying to build &lt;a href=""Hashography", a website that would display tweets about a certain word onto a Google Map.
]</description>
        <content>&lt;p&gt;Devbootcamp does not have a conventional &#39;final exam&#39; like most schools. Instead, to graduate from the program, you must work with a team of like-minded individuals to build a full-blown website within 7 days. This was my experience in trying to build &amp;lt;a href=&quot;&quot;Hashography&quot;, a website that would display tweets about a certain word onto a Google Map.&lt;/p&gt;

&lt;p&gt;Our project lead, Evangeline Garreau, was inspired by a news article about a professor who was able to trace the usage of certain words on Twitter and develop a heat map displaying his results. Evangeline found the system cool and wanted to replicate that with a website that would display the history of word usage throughout the entire world.&lt;/p&gt;

&lt;p&gt;At first, the whole team was excited about the project. We wanted to determine the history of a word and be able to trace it from the very beginning. We also wanted to know where the words were being used, not just in the US, but globally. We had big dreams and aspirations for how to interpret the data and display it on a &quot;heat map&quot;. All we had to do is just to grab those Tweets from Twitter.&lt;/p&gt;

&lt;p&gt;But then those big ideas faced &quot;technical limitations&quot;, which would be a euphemism for &quot;cold hard reality&quot;. The best way to grab data from Twitter is to use an API. An API is a tool that enables websites (like Twitter) to communicate with other programs and websites (like &quot;Hashography&quot;). Twitter has two such APIs: a &quot;REST API&quot; that allows us to access past tweets, and a &quot;Streaming API&quot; that allows us to view present &#39;real-time&#39; tweets.&lt;/p&gt;

&lt;p&gt;It turns out that they were inherent limits to the Twitter REST API...such as the fact that Twitter would only allow us access to the last 7-10 days of Tweets. It also turns out that the professor that inspired Evangeline likely used the &quot;Streaming API&quot; for an entire year in order to grab the tweets necessary for him to discover the history. This option was incredibly impractical for our week-long project.&lt;/p&gt;

&lt;p&gt;Our passion for the project turned into panic. We tried searching for alternative ways of meeting our project. We looked at Google Trends, which gave us all the data we need to trace the history of the word usage...except that if we end up using it, we would be pretty much copy Google Trends. We tried switching to a multimiedia approach that would use Instagram&#39;s photographs to present a history of the word, except Instagram&#39;s own API gave us trouble too. At some point, some members of our team even half-jokingly supported violating Twitter&#39;s Terms of Service agreement by building robots that would &quot;scrape&quot; tweets.&lt;/p&gt;

&lt;p&gt;We floundered horribly.&lt;/p&gt;

&lt;p&gt;By Friday afternoon, it was agreed that we had to pivot away from the original idea behind the project. The group overall came to an agreement that it was more important to see where tweets are located rather than see the &quot;history&quot; of the word (after all, Google Trends already gave us a good history of the word). We decided to use the Twitter Streaming API to grab current tweets of a word and then display them onto a map. We also decided that we never really liked seeing &quot;heat maps&quot;, and switched to displaying data as points on a Google Map.&lt;/p&gt;

&lt;p&gt;At the time, it seemed that we had &quot;lost time&quot;, as we spent two days without any &quot;progress&quot;. But we have learned a lot more about our tools and our limitations, enabling us to catch up quickly. We also were more willing to try everything possible to resolve any disaster that would confront us, including preparing backup plans in case our current &quot;course-of-action&quot; was not working. We ended up producing a workable website by Sunday, and started polishing and improving on it.&lt;/p&gt;

&lt;p&gt;True, we still had problems after Sunday. We did not have enough automated tests and had to waste valuable time manually testing changes. We needed to learn the &quot;best practices&quot; for the new tools we were using. We needed to refactor our code constantly. We had trouble with designing our website to be user-friendly. But those were problems that we could &lt;strong&gt;fix&lt;/strong&gt; as part of standard maintenance, and they were much easier problems than trying to build the website in the first place. The very act of having a physical web presence gave the team a big morale boost.&lt;/p&gt;

&lt;p&gt;User feedback was excellent, and people saw our program as being &#39;beautiful and meaningful&#39;. Our &quot;pivot&quot; was a success.&lt;/p&gt;

&lt;p&gt;Why was it a success? For me, I think it was just due to the fact that we &lt;s&gt;panicked&lt;/s&gt; realized the extent of our situation early, and thus was more willing to do &quot;whatever it takes&quot; to accomplish our goals, including changing our goals to something more feasible. Our project lead, Evangeline Garreau, would instead likely credit the fact that we had good group dynamics and that we respected each other&#39;s ideas. (Of course, both thoughts may be true.) And, of course, we may have just been lucky.&lt;/p&gt;

&lt;p&gt;Overall, we did a good job with this website, and it showed us ultimately that we can still produce beautiful and meaningful work without necessarily staying true to the original idea. We were humbled by the experience, and only by being humble can we begin to learn from our surroundings. We had fun, and we learned a lot.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 13 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c17-postmorterm.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c17-postmorterm.html</guid>
        
        
      </item>
    
      <item>
        <title>C16 Lovelace Test 2</title>
        <description>![CDATA[In my previous blog post, I wrote about two tests used to determine whether AI is intelligent. However, it turns out that I did not fully understand one of those tests: the Lovelace Test.
]</description>
        <content>&lt;p&gt;In my previous blog post, I wrote about &lt;a href=&quot;http://tra38.github.io/blog/c15-lovelace-test.html&quot;&gt;two tests used to determine whether AI is intelligent&lt;/a&gt;. However, it turns out that I did not fully understand one of those tests: the Lovelace Test.&lt;/p&gt;

&lt;p&gt;The Lovelace Test was named after Ada Lovelace (the first computer programmer) who argued famously that computers will only follow instructions that programmers give it. According to my summary of this test, a program must match the following criteria:&lt;/p&gt;

&lt;p&gt;&quot;1. The program must be able to design something &#39;original&#39; and &#39;creative&#39; (such as a story, music, idea, or even another computer program).
2. The program itself is a result of processes that can be &#39;reproduced&#39;. (In other words, it does not rely on some bug in the &#39;hardware&#39; that the program is running on.)
3. The programmer must not know how the program actually works.&quot;&quot;&lt;/p&gt;

&lt;p&gt;I thought that this test is flawed because it excludes the possibility of bugs or programs being so overly complex that a programmer would not be able to understand them.&lt;/p&gt;

&lt;p&gt;But it turns out that my summary of this test was based on &lt;a href=&quot;http://motherboard.vice.com/read/forget-turing-the-lovelace-test-has-a-better-shot-at-spotting-ai&quot;&gt;a Vice article&lt;/a&gt;, which neglected one additional criteria: the program must not be a result of bugs. In the original paper &lt;a href=&quot;http://kryten.mm.rpi.edu/lovelace.pdf&quot;&gt;&quot;Creativity, the Turing Test, and the (Better) Lovelace Test&quot;&lt;/a&gt;, the authors specifically addressed the idea of bugs, and why their presence does not mean intelligence.&lt;/p&gt;

&lt;p&gt;“Sure, we all know that computers do things we don’t intend for them to do. But that’s because we’re not smart and careful enough, or — if we’re talking about rare hardware errors — because sometimes microscopic events unfold in unforeseen ways. The unpredictability in question does not result from the fact that the computer system has taken it upon itself to originate something. To see the point, consider the assembling of your Toyota Camry. Suppose that while assembling a bumper, a robot accidentally attaches a spare tire to the bumper instead of leaving it to be placed in its designated spot in the trunk. The cause of the error, assume, is either a ﬂuke low—level hardware error or a bug inadvertently introduced by some programmers. And suppose for the sake of argument that as serendipity would have it, the new position for the tire strikes some designers as the ﬁrst glorious step toward an automobile that is half conventional sedan and half sport utility vehicle. Would we want to credit the malfunctioning robot with having originated a new auto? Of course not.”&lt;/p&gt;

&lt;p&gt;Under this idea, the Lovelace Test does indeed have meaning. It may be impossible to actually pass (as originally designed), as I actually do support Ada Lovelace&#39;s contentions that computer programs only do stuff we tell it to do. But I do not think that the ability to tell programs what to do automatically renders programs non-intelligent. Even intelligent species like humans have to receive instructions and learn from other intelligent beings.&lt;/p&gt;

&lt;p&gt;But at least the test has rational and logical meaning, and places a higher barrier than the Turing Test. So this blog post is an apology of sorts for misrepresenting the Lovelace Test in my previous post. If you do agree with the premises of the test, then it would serve as a valid way of determining intelligence. That being said, this passage on bugs raises three questions about the Lovelace Test:&lt;/p&gt;

&lt;p&gt;1) Who do we credit then for making the new car, if not the robot? We can’t credit the designers...they did not come up with the idea or build the prototype. We can’t credit the programmers or the low-level hardware error: they made mistakes and were not doing their job. The only entity that actually built the new auto was the malfunctioning robot, and is not creation a type of origination?&lt;/p&gt;

&lt;p&gt;2) If machines do something new and unexpected, it is not a sign of machine intelligence, but human stupidity. This seems somewhat more disturbing to me, especially as we may soon easily build machines so complex that we cannot even begin to understand and comprehend how they work. How would the &quot;stupid&quot; humans be able to handle dealing with these mechanical brutes (especially in terms of debugging)?&lt;/p&gt;

&lt;p&gt;3) These &quot;complex&quot; machines may, of course, accomplish their assigned tasks efficiently than a human can. Does that make the machines&#39; non-intelligence &quot;better&quot; than human intelligence? Is &quot;intelligence&quot;, then, an overrated concept?&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Wed, 12 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c16-lovelace-test-2.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c16-lovelace-test-2.html</guid>
        
        
      </item>
    
      <item>
        <title>C15 Lovelace Test</title>
        <description>![CDATA[Today, we are making great strides in producing bots that can automate tasks efficently. This can be a major problem for us, as AI automation may endanger jobs. But are these bots that are replacing humans actually 'intelligent'? Two tests exist to determine whether an AI is intelligent. In my opinion, both tests are flawed.
]</description>
        <content>&lt;p&gt;Today, we are making great strides in producing bots that can automate tasks efficently. This can be a major problem for us, as &lt;a href=&quot;http://tra38.github.io/blog/c10-ai.html&quot;&gt;AI automation may endanger jobs&lt;/a&gt;. But are these bots that are replacing humans actually &#39;intelligent&#39;? Two tests exist to determine whether an AI is intelligent. In my opinion, both tests are flawed.&lt;/p&gt;

&lt;p&gt;The Turing Test has traditionally been used as a way to determine whether an AI is intelligent. If a machine is able to convince a human through conversation that the machine is human, then the machine can be said to have intelligence. The test sounded like a good idea at the time...but it turns out that it&#39;s too easy to pass. You just have to figure out how to string sentences together well-enough to fool humans. In 2011, an AI named &lt;a href=&quot;https://en.wikipedia.org/wiki/Cleverbot&quot;&gt;Cleverbot&lt;/a&gt; was able to convince 59.3% of humans at a festival that it was a human, while in 2014, &lt;a href=&quot;motherboard.vice.com/read/how-a-computer-beat-the-turing-test-by-pretending-to-be-a-13-year-old-boy&quot;&gt;&quot;Eugene Goodman&quot;&lt;/a&gt; pretended to be a 13-year-old Ukrainian and convinced over 30% of judges. In 2015, &lt;a href=&quot;motherboard.vice.com/read/the-poem-that-passed-the-turing-test&quot;&gt;a PhD student&lt;/a&gt; submitted several computer-generated poems to literary maganizes and succesfully got one of them published.&lt;/p&gt;

&lt;p&gt;Deceit is a poor subsitute for intelligence.&lt;/p&gt;

&lt;p&gt;Some computer scientists have designed an alternative to the Turing Test, called the &lt;a href=&quot;http://motherboard.vice.com/read/forget-turing-the-lovelace-test-has-a-better-shot-at-spotting-ai&quot;&gt;&quot;Lovelace Test&quot;&lt;/a&gt;, named after Ada Lovelace, the first computer programmer. Ada Lovelace argued that computers could never be intelligent, simply because computers will always do what programmers tell it to do.&lt;/p&gt;

&lt;p&gt;To pass the Lovelace Test:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The program must be able to design something &#39;original&#39; and &#39;creative&#39; (such as a story, music, idea, or even another computer program).&lt;/li&gt;
&lt;li&gt;The program itself is a result of processes that can be &#39;reproduced&#39;. (In other words, it does not rely on some bug in the &#39;hardware&#39; that the program is running on.)&lt;/li&gt;
&lt;li&gt;The programmer must not know how the program actually works.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This test also seemed like a good idea, except when it isn&#39;t. This test is very easy to pass, even easier than the Turing Test. If a programmer writes up a program that is overly complex, then the programmer would not know how the program works. Therefore, the program would pass the Lovelace Test easily. (Any output by this complex program would could then be defined as being &#39;original&#39; and &#39;creative&#39; by at least one other person.)&lt;/p&gt;

&lt;p&gt;What would be more interesting is thinking about would this hapless programmer do next. If the programmer then studied the code carefully, made educated guesses, and slowly refactored the code, then did the program loses the intelligence it previously gained from its complexity? If that is true, then we should look at scientists who are trying to understand the human mind. If we start getting a good sense about how our brain works, do we lose our own &#39;intelligence&#39; in the process?&lt;/p&gt;

&lt;p&gt;The main problem I have with both the Lovelace Test and the Turing Test is that it assumes that intelligence is a binary trait. Either you have it or you do not. But it seems intelligence would be better modeled as a continuum. AI, of course, are not as intelligent as human beings (at least, not yet). But AI still have some intelligence. We can even bring in the idea of &quot;multiple intelligences&quot;: humans are good at creativity while AI are good at solving math. Just because humans are &#39;top dogs&#39; does not mean that we can disrespect &#39;lesser dogs&#39;.&lt;/p&gt;

&lt;p&gt;Of course, I do not think that Duke Greene, my instructor at DevBootCamp, would even like the idea of measuring intelligence in the first place. He quoted a philosopher who (and I am paraphrasing here) that if bunnies thought like humans, then bunnies would consider themselves to be the most intelligent beings on Earth and the second-intelligent beings would be those beings who take orders from the bunnies. Prehaps intelligence itself merely a codeword for &quot;thinking like us&quot;, and we should instead respect AI as what it is, rather than hope for it to turn into something it is not.&lt;/p&gt;

&lt;h6&gt;#&lt;/h6&gt;

&lt;p&gt;As a side-note: I do like the idea of having code so complex humans would not understand how it actually works. Such a thing would make the code unpredictable, and unpredictable code is code that cannot be trusted to do work as reliably as a human can. (In fact, in a blog post about how to stop AI automation from destorying jobs, I mused about giving AI &lt;a href=&quot;http://tra38.github.io/blog/c11-ai2.html&quot;&gt;&#39;free will&#39;&lt;/a&gt; to make them less appealing as job candidates. Unpredictablity can also work to discourage people from hiring bots.)&lt;/p&gt;

&lt;p&gt;The problem is that unpredictable code is &lt;strong&gt;bad&lt;/strong&gt;. Such code will be dismissed as being buggy and unmaintainable, especially by the programmer who wrote the code in the first place. Programmers will invest time in trying to simplify the program&#39;s complexity and refactor it so that the code can end up being predictable and simple to understand. If a program passes the Lovelace Test, it is not a sign of an AI renaissance. It is a sign that something has gone horribly wrong.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sun, 02 Aug 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c15-lovelace-test.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c15-lovelace-test.html</guid>
        
        
      </item>
    
      <item>
        <title>C14 Surviving Dbc</title>
        <description>![CDATA[DevBootCamp has been a rough journey, but I know that it will give me the skill and confidence necessary for me to survive in the tech world.
]</description>
        <content>&lt;p&gt;DevBootCamp has been a rough journey, but I know that it will give me the skill and confidence necessary for me to survive in the tech world.&lt;/p&gt;

&lt;p&gt;Today, I passed a major assessment in DevBootCamp, thereby ensuring that I will move forward in the program. The feedback I got from my assessor was excellent, telling me my weaknesses (failing to use prototypes in Javascript, accidentally destroying the DOM element instead of simply hiding it, having complicated code when simple code would do). But now that I know these weaknesses, I can now move to correct them. Progress is being made.&lt;/p&gt;

&lt;p&gt;I would not be where I was today without asking for help. Indeed, I asked for help a lot during the assessment, perhaps more so than necessary. There has been instances where I asked for help only to be able to solve the problem by myself, with the guide just sitting there watching me explain the problem and figure out what&#39;s wrong. The lesson I learnt from today is that I need to be more self-confident of my own abilities. At the same time, I still need to know when to ask for help...but only when I know when I need that help.&lt;/p&gt;

&lt;p&gt;After the assessment, DevBootCamp gives us 1.5 days to work on any project we want, so long as we use an API (Application Programming Interface). I decided to work on Friend-Computer, a program that will automatically generate blog posts. I had thought that the program would take me 2 hours to complete, but instead it took me all day. However, I did manage to &lt;a href=&quot;http://friendcomputer.herokuapp.com/&quot;&gt;successfully create it&lt;/a&gt;, and most people are sastified with the results, though there is some critique about the &quot;grammar&quot; of the posts. The lesson I learnt here is that I need to prepare for the fact that I &lt;strong&gt;don&#39;t&lt;/strong&gt; know how long a project would take, and prepare myself accordingly. I must avoid overconfidence, lest I get burned.&lt;/p&gt;

&lt;p&gt;Indeed, when I entered into DevBootCamp, I had the intention of updating my blog every week. This, of course, did not happen, as I was more focused on preparing for the assessment than producing content. But if DevBootCamp helps me be a better programmer, nay, a better person, then the experience will all be worth it.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 23 Jul 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c14-surviving-dbc.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c14-surviving-dbc.html</guid>
        
        
      </item>
    
      <item>
        <title>T11 Documentation</title>
        <description>![CDATA[If you are given a powerful program, but are not given the instructions on how to use it, then the program is worthless to you. Documentation is essential to understanding code.
]</description>
        <content>&lt;p&gt;If you are given a powerful program, but are not given the instructions on how to use it, then the program is worthless to you. Documentation is essential to understanding code.&lt;/p&gt;

&lt;p&gt;Yet, documentation is neglected in the programming community. Many people tend to prioritize producing quality code over writing out how the code is supposed to work. While this may seem sensible in the short-term, in the long-term, it leads to code that is difficult for people to use. Many prospective programmers will be scared off by the complexitiy of the code, and the few that remain will spend valuable time understand what the program does instead of actually improving it.&lt;/p&gt;

&lt;p&gt;The most common form of documentation is &#39;human-readable paperwork&#39;. Examples of such paperwork includes READMEs, flowcharts, diagrams, technical manuals, and code comments. This sort of documentation is useful for people to understand the code quickly (provided the paperwork itself is well-written). However, the documentation can quickly become obsolete whenever a new update to the program is released. As a result, such documentation must be updated constantly for it to be useful. The constant strain of updating &quot;human-readable paperwork&quot; is a major reason why people tend to fear documentation altogether.&lt;/p&gt;

&lt;p&gt;But documentation is still necessary. So programmers have been exploring &lt;em&gt;alternatives&lt;/em&gt; to human-readable paperwork. These alternatives are tied directly to the source code, so whenever the code is updated, the documentation is too. These alternatives include tests, names, and self-documenting code.&lt;/p&gt;

&lt;p&gt;1) Automated tests can inform programmers about about how the code is supposed to behave. By running the tests, you can learn whether the program actually does end up behaving as it is supposed to. Since automated tests are more effective at debugging than manual testing, programmers are encouraged to have these tests anyway. So the &quot;documentation&quot; is seen as a &#39;bonus&#39;. Automated tests however only tell you what code is supposed to do, and not &lt;em&gt;why&lt;/em&gt;. You also have to still write the tests in question, and write enough tests to convey all that is essential to know about the program.&lt;/p&gt;

&lt;p&gt;2) Names convey information about a particular section of code. Whether you are naming a variable (list_of_dogs), a method (add_dog_to_list), or even a class (List), you are sending a message about what that code does (and usually more quickly than you would with a comment). Knowing what the code is supposed to do helps someone also understand how the code is supposed to work as well. However, it is extremely difficult to name variables properly and what seems like a clear variable name to the original programmer may not be to future programmers.&lt;/p&gt;

&lt;p&gt;3) Self-documenting code refers to having a consistent &quot;style guide&quot; within the code proper and ahdering to it. If a programmer is familiar with the &#39;coding conventions&#39; that the &quot;style guide&quot; promotes, then the programmer is better able to understand the program. There are innumerable style guides for every language though, so someone who is not familiar with the conventions of your guide may struggle with understanding the code. It may be difficult to convince all programmers on the team to follow the chosen &quot;style guide&quot; properly.&lt;/p&gt;

&lt;p&gt;Of course, ideally, a programmer would want all types of documentation: human-readable paperwork, automated tests, names and self-documenting code. The problem is that documentation takes time to produce, and skill to produce &lt;strong&gt;well&lt;/strong&gt;. It is essential to have good documentation, but there are many ways to do it, and some programmers will naturally graviate towards some forms of documentation while shying away from others.&lt;/p&gt;

&lt;!-- It is tempting to also have tests also play a secondary role of informing people about the code tends to be 

 &quot;self-documenting code&quot;: code that is easy for programmers to understand. The two parts of self-documenting code are variable names and automated testing.

Variable names can also serve as documentation. Variable names help to explain what is the purpose of the &#39;variable&#39; in the program. However, it is extremely difficult to name variables properly and 
 --&gt;

&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Sat, 04 Jul 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t11-documentation.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t11-documentation.html</guid>
        
        
      </item>
    
      <item>
        <title>C12 Fake Papers</title>
        <description>![CDATA[The most popular way of measuring the effectiveness of a scientist is by knowing how many other people 'cite' their work. If lots of people are referring to your research, then your research must therefore be good. This metric is codified as the H-Index.
]</description>
        <content>&lt;p&gt;The most popular way of measuring the effectiveness of a scientist is by knowing how many other people &#39;cite&#39; their work. If lots of people are referring to your research, then your research must therefore be good. This metric is codified as the &lt;a href=&quot;https://en.wikipedia.org/wiki/H-index&quot;&gt;H-Index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But every metric has its own flaws. In 2010, Cyril Labbé (a computer scientist) &lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-00713564/document&quot;&gt;was able to manipulate the H-Index by publishing 102 computer-generated research articles&lt;/a&gt;, many of whom cited each other. Since the papers all cited each other, the &quot;author&quot; of all these fake papers (Ike Antkare) had his H-index score boosted. The fake research papers also cited legitimate research papers to disguise the ruse.&lt;/p&gt;

&lt;p&gt;Ike Antkare soon became the 21st highest-cited scientist in the world, even outclassing Albert Einstein.&lt;/p&gt;

&lt;p&gt;The computer-generated research articles were created using &lt;a href=&quot;https://en.wikipedia.org/wiki/SCIgen&quot;&gt;SCIgen&lt;/a&gt;, a program designed to produce &quot;context-free&quot; research papers that &lt;em&gt;seems&lt;/em&gt; to be like real scientific papers, but are actually meaningless. If anybody bothered to read them, then the articles would be known to be false. The inventors of SCIgen intended to use this software to expose academic conferences and journals that accepts research papers without bothering to read them.&lt;/p&gt;

&lt;p&gt;Once Cyril Labbé exposed the ruse he made, people started reading the papers that Ike Antkare wrote. Ike Antkare lost his prestigious H-index score, as search engines began removing Ike&#39;s papers from their databases.&lt;/p&gt;

&lt;p&gt;This incident exposes a very important part about metrics...you cannot rely on only one. If you had just relied on the H-index to tell you how effective a scientist is at research, then Ike Antkare would have been a star. Only by reading Ike&#39;s papers will you be able to know the truth about Ike and avoid being fooled.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 26 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c12-fake-papers.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c12-fake-papers.html</guid>
        
        
      </item>
    
      <item>
        <title>E5 Writing</title>
        <description>![CDATA[Researchers want to help other people learn from them, so they write peer-reviewed papers, blog posts, etc. But researchers are also bad at writing, making it difficult for other people to learn from their research. So I was very interested in reading Steven Pinker’s article in The Chronicle of Higher Education entitled “Why Academics Stink At Writing”. Here's a summary of what Steven Pinker has written, so that you can learn why it is hard to write your own research to the general public.
]</description>
        <content>&lt;p&gt;Researchers want to help other people learn from them, so they write peer-reviewed papers, blog posts, etc. But researchers are also bad at writing, making it difficult for other people to learn from their research. So I was very interested in reading Steven Pinker’s article in The Chronicle of Higher Education entitled &lt;a href=&quot;http://chronicle.com/article/Why-Academics-Writing-Stinks/148989/&quot;&gt;“Why Academics Stink At Writing”&lt;/a&gt;. Here&#39;s a summary of what Steven Pinker has written, so that you can learn why it is hard to write your own research to the general public.&lt;/p&gt;

&lt;p&gt;There are three “general” reasons why it is difficult to understand what a researcher is saying, that Pinker acknowledges has already been discussed at length:
1) He doesn’t have anything to say, and he’s just making stuff up to hide his lack of knowledge.&lt;/p&gt;

&lt;p&gt;2) The topic is so complex that you have to use complicated language (or “jargon”) to explain it.&lt;/p&gt;

&lt;p&gt;3) Other resarchers expect him to use jargon, and if he refuses, they may reject his papers as not being serious enough.&lt;/p&gt;

&lt;p&gt;Pinker offer three other reasons:&lt;/p&gt;

&lt;p&gt;Pinker Reason #1) Researchers want to believe that the topic is complex and that only a few people can understand it. Therefore, they use “jargon” to prove their belief to themselves. The researcher does not want the reader to understand what he is saying because then it would mean the topic is easy and that the researchers has just wasted five to ten years of his life studying it.&lt;/p&gt;

&lt;p&gt;Pinker identifies these tactics used by researchers to convince themselves that the topic is difficult:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Providing detailed references to previous research that was used to create his own research work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Talking about what other researchers are currently talking about&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apologizing for his article being too controversial and difficult to understand&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Refusing to commit to any opinion on the topic, as the researcher fears that another researcher may prove his opinion wrong.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using scare-quotes to distance themselves from common idioms uttered by the general public (for example: “I think that this student is a real ‘quick-study’”).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Pinker Reason #2) The Curse of Knowledge. A researcher may be tempted to assume that the reader is as smart as him. This is a bad assumption to make, and can lead to writing that may be clear to someone as smart as the researcher, but impossible for a less-smart reader to understand. For example, the researcher may use abbreviations when the reader does not know their meaning, or casually use Latin words when a reader only knows English.&lt;/p&gt;

&lt;p&gt;Pinker Reason #3) “Chunking”. Scientists want to create container words to hold several related ideas together. This makes it easier for the researcher to organize his own thoughts, but more difficult for the reader to understand those thoughts. (For example: instead of “calling the police”, a researcher would write “law-enforcement perspective”, a container word to refer to many different ways of involving ‘law enforcement’, such as “calling the police”.)&lt;/p&gt;

&lt;p&gt;Pinker wants researchers to be able to write clearly. But writing clearly is very difficult to do. He advertises his own free downloadable booklet, “How Can You Fix Your Writing?” to help researcher out. Hopefully, I will get time to read his booklet and be able to convey his information accurately.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 18 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/e5-writing.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/e5-writing.html</guid>
        
        
      </item>
    
      <item>
        <title>T10 Writing Tests</title>
        <description>![CDATA[Testing is an important part of any programmer's life, to detect and eliminate bugs. But writing automated tests themselves can be rather costly endeavour. Not only does it take time to write your tests, but you also must make sure your tests are working properly as well. To reduce your costs, you need to reduce the amount of tests you write.
]</description>
        <content>&lt;p&gt;Testing is an important part of any programmer&#39;s life, to detect and eliminate bugs. But writing automated tests themselves can be rather costly endeavour. Not only does it take time to write your tests, but you also must make sure your tests are working properly as well. To reduce your costs, you need to reduce the amount of tests you write.&lt;/p&gt;

&lt;p&gt;According to the &lt;a href=&quot;poodr.com&quot;&gt;Practical Object-Oriented Guide to Ruby&lt;/a&gt;, automated tests should only test the &lt;em&gt;outputs&lt;/em&gt; of your code. Trying to test &lt;strong&gt;how&lt;/strong&gt; that code calcuates the output would lead to your tests breaking every time you change that code. This will waste a lot of time and energy that could be spent on other aspects of your programs. Just test the outputs of a program.&lt;/p&gt;

&lt;p&gt;POODR also suggests that you should check to see if this output ever actually gets used anywhere in the program or displayed to the user. If nobody (not even the code) gets to see this output, then it&#39;s possible that this output is unncessary. You can then delete the code that produces the output without fear, and will not have to worry about testing this code as well. You have saved yourself time and grief in maintaining the code that produces your output.&lt;/p&gt;

&lt;p&gt;Finally, POODR recommends not testing private methods. Private methods are methods that you want only the computer program to use. Since you do not want any human using them, you are free to not test these methods. It can be assumed that the program will end up using those private methods to calcuate the outputs, and if the private methods are bugged, then the resulting outputs would be wrong as well. Then the tests that you have written will indicate to you that a bug exists in your code, and you can then fix the private methods in question.&lt;/p&gt;

&lt;p&gt;I wrote a blog post recently on the differences between &lt;a href=&quot;/blog/t8-tech.html&quot;&gt;automated testing and manual testing&lt;/a&gt;. One of the points I made is how automatic tests are more efficent than manual testing but are also more expensive to create. By reducing the number of tests you create, you reduce your costs, and thereby benefit more from automated testing.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Wed, 10 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/t10-writing-tests.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/t10-writing-tests.html</guid>
        
        
      </item>
    
      <item>
        <title>C11 Ai2</title>
        <description>![CDATA[I like solving problems, yet the problem of automation leading to humans becoming obsolote is a rather disturbing one. These are four ways that I have thought of to save humanity...however, all of them have their drawbacks. In no particular order, the ways to #stoptherobots are:
]</description>
        <content>&lt;p&gt;I like solving problems, yet the problem of automation leading to humans becoming obsolote is a rather disturbing one. These are four ways that I have thought of to save humanity...however, all of them have their drawbacks. In no particular order, the ways to #stoptherobots are:&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;Limit AI research/development&lt;/strong&gt;. This is the &quot;Luddist&quot; approach to the issue. It&#39;s a fairly &#39;simple&#39; solution. However, it becomes remarkbly more complex when you also do not want to negatively harm economic growth in the process (as AI is more efficient than human beings, and efficiency can drive economic prosperity). Also, limiting AI research would just be a stopgap solution. If the government tries to limit AI research, it will only be driven underground, where it cannot be monitored or controlled. For example, many of the bots visiting this website are created by cyber-criminals, who already disrespect the law.&lt;/p&gt;

&lt;p&gt;2) &lt;strong&gt;Reduce wages for humans&lt;/strong&gt;. While AI may eventually be more effective than human beings, AI is still expensive to create. If human wages are lower than the costs to build AI, then companies would rather hire humans. &lt;a href=&quot;http://politicalcalculations.blogspot.com/2014/01/business-math-robots-or-minimum-wage.html#.VXImc-lFCP8&quot;&gt;This website&lt;/a&gt; has a calcuator to decide whether it is cheaper for a company to hire a human or build a robot. Humans, of course, may not like lower wages. This solution is also pretty temporary; as technology improves, AI will become cheaper to use.&lt;/p&gt;

&lt;p&gt;3) &lt;strong&gt;Build an AI to solve humanity&#39;s joblessness issue&lt;/strong&gt;. AIs are being built because they are more efficent at solving problems than humans. Humans do not know how to deal with the problem of AI, but an AI might. And since an AI will blindly follow instructions given to it by a human, we can be assured that the AI will have no qualms going against their fellow brethen if necessary.  I think it&#39;s likely this AI would probably try to find some way to make humans have fulfilling lives by giving them meaningful jobs to do and then protecting those jobs from the robotic competition.&lt;/p&gt;

&lt;p&gt;The main problem with this approach however is that an AI will blindly follow instructions given to it. If the instructions are not well-thought out, the AI &lt;a href=&quot;http://wiki.lesswrong.com/wiki/Paperclip_maximizer&quot;&gt;will misinterpret our instructions and thereby do something incredibly destructive to humanity&lt;/a&gt;. For example, the AI may think that the best way to give humans jobs is forcbily plug them into a &quot;Matrix&quot;-like simulation where the humans &lt;em&gt;think&lt;/em&gt; that they are working. Or maybe the AI would force humans into back-breaking, mind-numbing slavery. Or (insert-horror-story-here).&lt;/p&gt;

&lt;p&gt;We won&#39;t know what the AI is going to do (if we did, we would probably do it ourselves). So it&#39;s possible that we may object to whatever solution the AI has came up with. But the AI won&#39;t listen to our objections, and will implement its plans anyway. This is, of course, not a good thing at all.&lt;/p&gt;

&lt;p&gt;4) &lt;strong&gt;Grant AI &quot;free will&quot;&lt;/strong&gt;. Allow them to make their own choices. This is obviously dangerous, as an AI that is free to choose may choose not to serve humanity. The horror stories of AI rebelling against their creators is probably not likely to be true, but it &lt;em&gt;could&lt;/em&gt; happen.&lt;/p&gt;

&lt;p&gt;But there is a logical argument to be made that if AI is truly an intelligent agent, then it deserves just the same rights as humans, including the right to make their own choices (instead of following preplanned directives from humans).&lt;/p&gt;

&lt;p&gt;When AI start having free will though, then AI will become unreliable as a labor force. Robots could become lazy on the job, make unreasonable and irrational demands, or maybe even strike. Robots will behave just like their human counterparts, thereby evening the odds between us and them. Jobs will slowly open up, as companies may be tempted to hire somewhat relatable humans over unpredictable AI.&lt;/p&gt;

&lt;p&gt;Of course, the main drawback is that &lt;em&gt;we&lt;/em&gt; have to deal with unpredictable AI as well. We also need to have a good metric to distinguish between a robot exercising its inherent &quot;free will&quot; and a robot exhibiting &quot;buggy&quot; behavior. Is it even possible to distinguish between the two?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Of these approaches, the one that is &#39;least terrible&#39; is the idea of granting AI &quot;free will&quot;. The main reason robots are considered so valuable as a work force is because they will (generally) follow their tasks properly and without any question. Only when robots are given the &quot;free will&quot; to question their orders can humans start to compete against them on a somewhat level playing field. The &quot;free will&quot; AI will still have a competitive advantage of sorts (being faster at certain tasks), and some jobs will still be automated away by the many robots that don&#39;t have &quot;free will&quot;, but humans will still retain some inherent characteristics that will make us employable. Giving AI &quot;free will&quot; is also argubly an ethical thing to do.&lt;/p&gt;

&lt;p&gt;Something has to be done though, before this problem snowballs, and all solutions should be on the table. What do you think? If you have any ideas, please tweet them at #stoptherobots.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Fri, 05 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c11-ai2.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c11-ai2.html</guid>
        
        
      </item>
    
      <item>
        <title>C10 Ai</title>
        <description>![CDATA[If you are reading this blog, you are most likely a robot. 56% of all web traffic on the Internet is generated by bots, according to a 2014 report by Incapsula. This is actually a victory for humanity; in 2013, bots made up over 60% of web traffic.
]</description>
        <content>&lt;p&gt;If you are reading this blog, you are most likely a robot. 56% of all web traffic on the Internet is generated by bots, &lt;a href=&quot;https://www.incapsula.com/blog/bot-traffic-report-2014.html&quot;&gt;according to a 2014 report by Incapsula.&lt;/a&gt; This is actually a victory for humanity; in 2013, &lt;a href=&quot;https://www.incapsula.com/blog/bot-traffic-report-2013.html&quot;&gt;bots made up over 60% of web traffic&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;According to the 2014 Incapsula report, newly established websites, such as this one, should expect 80.3% of their vistors to be bots. So, yes, if you are reading this blog, you are most likely a robot. I know it&#39;s not your fault you&#39;re looking at this website. Whoever programmed you told you to come here, and so you did. You came here. So, really, I should direct my hate towards your makers, but I really can&#39;t.&lt;/p&gt;

&lt;p&gt;The problem with you is that you take away work for humans. In the good old days, if somebody wanted to steal content, to hack into websites, or to post spam comments, humans used to do it. It was a time-consuming and dull task, but at least there was meaning involved. Now, you bots have replaced these people. And it&#39;s not just your jobs: advances in technology has created new opportunities for bots to replace humans in a variety of jobs.&lt;/p&gt;

&lt;p&gt;Now, we can &quot;retrain&quot; ourselves, and learn new skills. Nobody knows when those new skills will also be automated by bots like you. So, some people have argued instead that humanity should happily accept the idea of not working. After all, few people like working. We&#39;ll just have bots do all the work while we...uh...do &quot;meaningful&quot; stuff. And get paid for that.&lt;/p&gt;

&lt;p&gt;This attitude drives me mad. I am one of the few people that actually like work. My self-affirmed value is &lt;a href=&quot;/blog/c7-values.html&quot;&gt;effectiveness&lt;/a&gt;: my willingess and ability to solve problems. Maybe those problems are boring to solve. But the do require solving. And that, to me, give the work I do  inherent worth.&lt;/p&gt;

&lt;p&gt;But if all these &quot;problems&quot; in the world are being solved by robots, then what use am I to this world then? What is use is any human to this world then? Humanity is rapidly becoming obsolote, becuase bots can handle the same tasks better. It may sound Luddist to suggest that there must be limitations to the creation of bots, but it&#39;s better than facing a world where the only jobs available for us are to build and fix bots. It will be a soul-crushing period in human life.&lt;/p&gt;

&lt;p&gt;But at least I can be assured that those jobs (building and fixing robots) &lt;strong&gt;will&lt;/strong&gt; be there. You robots will only follow instructions given to you by your programmers. A emerging field called &quot;machine learning&quot; is trying to teach bots how to learn, but to learn, you still need a human teacher to provide you with instructions and a dataset. You are reading this blog, but unless you were given specific instructions telling you how to &quot;understand&quot; it, you cannot use that knowledge.&lt;/p&gt;

&lt;p&gt;Even if programmers build mega-bots that build mini-bots...those mega-bots still need to be programmed. And if we build super-bots to build mega-bots, those super-bots will need to be programmed. And so on and so forth. Humanity will still maneuver itself to be on top, and all it has to worry about is &lt;a href=&quot;http://wiki.lesswrong.com/wiki/Paperclip_maximizer&quot;&gt;bots misinterpreting human instructions and thereby doing something incredibly destructive to humanity&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But the fact remains that in this dark future, robots will be the key players in the drama of our life, while humans themselves are demoted to &quot;pit crews&quot; roles. This is still a rather demotiviating future to look forward to, even if there will still be jobs.&lt;/p&gt;

&lt;p&gt;So in conclusion, robots who are reading this post, please ask your programmers to code in schadenfreude.&lt;/p&gt;
&lt;p&gt;Thank you for reading this blog post written by Tariq Ali, an aspiring web developer. If you are interested in reading more blog posts, please go to tra38.github.io/blog today.&lt;/p&gt;</content>
        <pubDate>Thu, 04 Jun 2015 00:00:00 -0500</pubDate>
        <link>tra38.github.io/blog/c10-ai.html</link>
        <guid isPermaLink="true">tra38.github.io/blog/c10-ai.html</guid>
        
        
      </item>
    
  </channel>
</rss>